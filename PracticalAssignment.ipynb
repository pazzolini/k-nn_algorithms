{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca115697-df76-49ee-b90d-575a58125301",
   "metadata": {},
   "source": [
    "## Machine Learning I (CC2008) - Practical Assignment (2023-24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e147ff8-1b24-40e4-9628-e4d2a0910a3b",
   "metadata": {},
   "source": [
    "# Evaluation and Comparison of K-NN Algorithms on Imbalanced Binary Classification Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9c258d-a25f-44fa-aca1-9ca7939c04af",
   "metadata": {},
   "source": [
    "#### VÃ­tor Bruno Dantas Ramalhosa Ferreira (201109428) | G: 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6b3761-0900-47a7-bb2c-73561b2aa799",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "- [1. Algorithm Selection](#1-Algorithm)\n",
    "- [2. K-NN and Data Characteristics](#2-KNN)\n",
    "- [3. Class Imbalance in Binary Problems](#3-Class-imbalance)\n",
    "- [4. Benchmark First Evaluation](#4-Benchmark-first-evaluation)\n",
    "    - [4.1. Datasets Selection](#4.1-DS-selection)\n",
    "    - [4.2. Datasets Evaluation](#4.2-DS-evaluation)\n",
    "        - [4.2.1. wilt](#4.2.1-wilt) \n",
    "        - [4.2.2. sick](#4.2.2-sick)\n",
    "        - [4.2.3. ozone-level-8hr](#4.2.3-ozone)\n",
    "        - [4.2.4. pc1](#4.2.4-pc1)\n",
    "        - [4.2.5. climate-model-simulation-crashes](#4.2.5-climate)\n",
    "        - [4.2.6. pc3](#4.2.6-pc3)    \n",
    "        - [4.2.7. pc4](#4.2.7-pc4)\n",
    "        - [4.2.8. Internet-Advertisements](#4.2.8-internet)\n",
    "        - [4.2.9. churn](#4.2.9-churn)\n",
    "        - [4.2.10. kc1](#4.2.10-kc1)\n",
    "    - [4.3. Results](#4.3-Results)    \n",
    "- [5. K-NN's variant proposal and implementation](#5-KNN-variant-proposal)\n",
    "- [6. Benchmark Second Evaluation](#6-Benchmark-second-evaluation)\n",
    "    - [6.1. Datasets Evaluation](#6.1-DS-evaluation)\n",
    "        - [6.1.1. wilt](#6.1.1-wilt) \n",
    "        - [6.1.2. sick](#6.1.2-sick)\n",
    "        - [6.1.3. ozone-level-8hr](#6.1.3-ozone)\n",
    "        - [6.1.4. pc1](#6.1.4-pc1)\n",
    "        - [6.1.5. climate-model-simulation-crashes](#6.1.5-climate)\n",
    "        - [6.1.6. pc3](#6.1.6-pc3)    \n",
    "        - [6.1.7. pc4](#6.1.7-pc4)\n",
    "        - [6.1.8. Internet-Advertisements](#6.1.8-internet)\n",
    "        - [6.1.9. churn](#6.1.9-churn)\n",
    "        - [6.1.10. kc1](#6.1.10-kc1)\n",
    "    - [6.2. Results and Discussion](#6.2-Results)\n",
    "- [7. References](#7-References)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598660af-266d-412e-a5a8-7f7a4394b533",
   "metadata": {},
   "source": [
    "<a id=\"1-Algorithm\"></a>\n",
    "## 1. Algorithm Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9b2b96-aed8-41e5-ba83-fea392454279",
   "metadata": {},
   "source": [
    "For the machine learning tasks outlined in this assignment, I have selected the **K-Nearest Neighbors (K-NN)** algorithm. K-NN is renowned for its simplicity and effectiveness, especially in scenarios where the decision boundary is irregular. The algorithm's reliance on feature similarity (distance metrics) to predict the labels of new data points makes it a versatile choice for many practical applications.\n",
    "\n",
    "A standard implementation of the K-NN algorithm, which was later used, can be found at this GitHub repository: [MLAlgorithms - KNN](https://github.com/rushter/MLAlgorithms/blob/master/mla/knn.py).\n",
    "\n",
    "This approach ensures that the fundamental aspects of the algorithm are adhered to, including distance calculation, neighbor selection, and classification based on majority voting. Below are the needed classes for the K-NN functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b067dc-11eb-4e33-bda6-eb59c34cadd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "class BaseEstimator:\n",
    "    y_required = True\n",
    "    fit_required = True\n",
    "\n",
    "    def _setup_input(self, X, y=None):\n",
    "        \"\"\"Ensure inputs to an estimator are in the expected format.\n",
    "\n",
    "        Ensures X and y are stored as numpy ndarrays by converting from an\n",
    "        array-like object if necessary. Enables estimators to define whether\n",
    "        they require a set of y target values or not with y_required, e.g.\n",
    "        kmeans clustering requires no target labels and is fit against only X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like\n",
    "            Feature dataset.\n",
    "        y : array-like\n",
    "            Target values. By default is required, but if y_required = false\n",
    "            then may be omitted.\n",
    "        \"\"\"\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            X = np.array(X)\n",
    "\n",
    "        if X.size == 0:\n",
    "            raise ValueError(\"Got an empty matrix.\")\n",
    "\n",
    "        if X.ndim == 1:\n",
    "            self.n_samples, self.n_features = 1, X.shape\n",
    "        else:\n",
    "            self.n_samples, self.n_features = X.shape[0], np.prod(X.shape[1:])\n",
    "\n",
    "        self.X = X\n",
    "\n",
    "        if self.y_required:\n",
    "            if y is None:\n",
    "                raise ValueError(\"Missed required argument y\")\n",
    "\n",
    "            if not isinstance(y, np.ndarray):\n",
    "                y = np.array(y)\n",
    "\n",
    "            if y.size == 0:\n",
    "                raise ValueError(\"The targets array must be no-empty.\")\n",
    "\n",
    "        self.y = y\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self._setup_input(X, y)\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            X = np.array(X)\n",
    "\n",
    "        if self.X is not None or not self.fit_required:\n",
    "            return self._predict(X)\n",
    "        else:\n",
    "            raise ValueError(\"You must call `fit` before `predict`\")\n",
    "\n",
    "    def _predict(self, X=None):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class KNNBase(BaseEstimator):\n",
    "    def __init__(self, k=5, distance_func=euclidean):\n",
    "        \"\"\"Base class for Nearest neighbors classifier and regressor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        k : int, default 5\n",
    "            The number of neighbors to take into account. If 0, all the\n",
    "            training examples are used.\n",
    "        distance_func : function, default euclidean distance\n",
    "            A distance function taking two arguments. Any function from\n",
    "            scipy.spatial.distance will do.\n",
    "        \"\"\"\n",
    "\n",
    "        self.k = None if k == 0 else k  # l[:None] returns the whole list\n",
    "        self.distance_func = distance_func\n",
    "\n",
    "    def aggregate(self, neighbors_targets):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def _predict(self, X=None):\n",
    "        predictions = [self._predict_x(x) for x in X]\n",
    "\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _predict_x(self, x):\n",
    "        \"\"\"Predict the label of a single instance x.\"\"\"\n",
    "\n",
    "        # compute distances between x and all examples in the training set.\n",
    "        distances = (self.distance_func(x, example) for example in self.X)\n",
    "\n",
    "        # Sort all examples by their distance to x and keep their target value.\n",
    "        neighbors = sorted(((dist, target) for (dist, target) in zip(distances, self.y)), key=lambda x: x[0])\n",
    "\n",
    "        # Get targets of the k-nn and aggregate them (most common one or\n",
    "        # average).\n",
    "        neighbors_targets = [target for (_, target) in neighbors[: self.k]]\n",
    "\n",
    "        return self.aggregate(neighbors_targets)\n",
    "\n",
    "\n",
    "class KNNClassifier(KNNBase):\n",
    "    \"\"\"Nearest neighbors classifier.\n",
    "\n",
    "    Note: if there is a tie for the most common label among the neighbors, then\n",
    "    the predicted label is arbitrary.\"\"\"\n",
    "\n",
    "    def aggregate(self, neighbors_targets):\n",
    "        \"\"\"Return the most common target label.\"\"\"\n",
    "\n",
    "        most_common_label = Counter(neighbors_targets).most_common(1)[0][0]\n",
    "        return most_common_label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20085d6-0300-433a-b26b-fde8b69047ba",
   "metadata": {},
   "source": [
    "This chosen implementation served as the base for the modifications or enhancements, which were later explored in the assignment, particularly when proposing and implementing a **variant of the K-NN algorithm**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a6a79e-29a9-4dca-8e8e-bf88837ba0ab",
   "metadata": {},
   "source": [
    "<a id=\"2-KNN\"></a>\n",
    "## 2. K-NN and Data Characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86f0b9d-5f51-4823-aa30-448cca29c26d",
   "metadata": {},
   "source": [
    "The **K-Nearest Neighbors (K-NN)** algorithm, while straightforward and versatile, is notably sensitive to the specific characteristics of the dataset it processes. Below, I hypothesized how the standard version of K-NN reacts to various data peculiarities and which characteristics may most significantly impact its performance.\n",
    "\n",
    "1. **Qualitative Attributes with a Large Number of Possible Values**\n",
    "K-NN relies heavily on distance metrics to make predictions, which can become problematic when dealing with qualitative or categorical attributes that have a wide range of values. If these attributes are encoded improperly (e.g., using simple integer encoding), distances between categories may not be meaningful, leading to poor performance. Techniques like one-hot encoding can alleviate this issue but increase the dimensionality of the data, which can exacerbate the curse of dimensionality.\n",
    "\n",
    "2. **Noise or Outliers**\n",
    "The presence of noise or outliers in the training data can disproportionately affect K-NN because the algorithm's predictions are directly influenced by the nearest few samples in the feature space. An outlier close to a query point can lead the algorithm to make incorrect predictions, especially if the number of neighbors k is small.\n",
    "\n",
    "3. **Class Imbalance in Binary Problems**\n",
    "In binary classification tasks where one class significantly outnumbers the other, K-NN can develop a bias towards the majority class. This happens because there is a higher probability that the majority of the nearest neighbors belong to the more prevalent class, which can mislead predictions.\n",
    "\n",
    "4. **Multiclass Classification**\n",
    "In multiclass settings, K-NNâs efficacy can diminish as the distance between neighbors becomes less discriminative. When classes are numerous, the likelihood increases that neighbors belong to several different classes, which can dilute the voting process and lead to less confident predictions.\n",
    "\n",
    "5. **Class Overlap**\n",
    "K-NN's performance is also compromised in situations where class boundaries overlap significantly. In such cases, the local neighborhood of a sample may contain instances from multiple classes, making it difficult for K-NN to accurately assign a class based on majority voting.\n",
    "\n",
    "In summary, the standard implementation of K-NN is inherently sensitive to the aforementioned data characteristics due to its dependency on local information and distance calculations. This sensitivity stems primarily from:\n",
    "\n",
    "- **Dependency on Local Structure**: K-NN's decision-making process is based purely on the nearest neighbors, with no understanding of the overall data structure. This makes it highly susceptible to anomalies in local data patterns.\n",
    "- **Equal Weight to All Features**: Standard K-NN implementation gives equal importance to all features unless explicitly programmed to do otherwise, which can lead to issues when irrelevant or less important features influence the distance calculations.\n",
    "- **Curse of Dimensionality**: As the number of features grows (a common scenario when encoding categorical variables or dealing with high-dimensional data), the volume of the feature space increases exponentially, and the data becomes sparser. This sparsity makes it harder for K-NN to find meaningful neighbors, as most points are almost equidistant to one another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa229d0-97fa-4cb8-951f-d1b01648fe12",
   "metadata": {},
   "source": [
    "<a id=\"3-Class-imbalance\"></a>\n",
    "## 3. Class Imbalance in Binary Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d5e721-b30f-4ec9-ae12-63af25c14fab",
   "metadata": {},
   "source": [
    "**Class imbalance** is a critical data characteristic to address in binary classification problems, especially when using algorithms like K-Nearest Neighbors (K-NN). This issue arises when one class in the dataset significantly outnumbers the other, which can alter the predictive accuracy and lead to a model that is biased toward the majority class. Understanding and tackling class imbalance is essential for several reasons:\n",
    "\n",
    "- **Bias Towards Majority Class**: In its standard form, K-NN uses a majority voting system where the class label of a new instance is determined based on the most common class among its nearest neighbors. If one class dominates the dataset, it's more likely that a new instance will be classified into the majority class regardless of its true label. This results in poor model performance, particularly in its ability to correctly identify instances of the minority class.\n",
    "- **Degradation of Performance Metrics**: Class imbalance affects key performance metrics. For instance, accuracy might appear high, but this can be misleading if the algorithm simply predicts the majority class most of the time. More critical metrics in imbalanced settings, like precision, recall, and the F1-score for the minority class, often degrade unless the imbalance is addressed.\n",
    "- **Practical Implications in Real-World Scenarios**: Many real-world applications involve scenarios where the minority class is of greater interest despite its fewer occurrences, such as fraud detection, disease diagnosis, or spam detection. In these cases, failing to correctly predict the minority class can have serious consequences, making it imperative to handle class imbalance effectively.\n",
    "- **Fairness and Equity in Predictive Modeling**: Addressing class imbalance also touches on ethical aspects of machine learning. Models trained on imbalanced data can perpetuate or exacerbate biases, leading to unfair outcomes. Ensuring that the model treats classes equitably is crucial to ethical AI practices.\n",
    "\n",
    "Given these considerations, tackling class imbalance is not merely a technical issue but also a fundamental aspect of building reliable, fair, and effective machine learning models. Addressing this imbalance allows for a more nuanced understanding of the dataset and improves the robustness of the model's predictions across different classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41791956-4bbb-4977-8e51-f8f961e99072",
   "metadata": {},
   "source": [
    "<a id=\"4-Benchmark-first-evaluation\"></a>\n",
    "## 4. Benchmark First Evaluation\n",
    "\n",
    "<a id=\"4.1-DS-selection\"></a>\n",
    "### 4.1. Datasets Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f420a90-e697-4ed3-a2c6-5a9439fba277",
   "metadata": {},
   "source": [
    "For the initial benchmarking of the provided K-NN implementation, the algorithm performance was evaluated using the **OpenML-CC18 Curated Classification Benchmark**. This benchmark suite provides a variety of datasets specifically curated for comprehensive benchmarking of classification algorithms. \n",
    "\n",
    "Below is a list of the given datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "658e6870-ea0a-4bd0-a6b6-1abfefb7c953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Datasets in OpenML-CC18 Curated Classification benchmark:\n",
      "\n",
      "Dataset ID: 3, Name: kr-vs-kp\n",
      "Dataset ID: 6, Name: letter\n",
      "Dataset ID: 11, Name: balance-scale\n",
      "Dataset ID: 12, Name: mfeat-factors\n",
      "Dataset ID: 14, Name: mfeat-fourier\n",
      "Dataset ID: 15, Name: breast-w\n",
      "Dataset ID: 16, Name: mfeat-karhunen\n",
      "Dataset ID: 18, Name: mfeat-morphological\n",
      "Dataset ID: 22, Name: mfeat-zernike\n",
      "Dataset ID: 23, Name: cmc\n",
      "Dataset ID: 28, Name: optdigits\n",
      "Dataset ID: 29, Name: credit-approval\n",
      "Dataset ID: 31, Name: credit-g\n",
      "Dataset ID: 32, Name: pendigits\n",
      "Dataset ID: 37, Name: diabetes\n",
      "Dataset ID: 44, Name: spambase\n",
      "Dataset ID: 46, Name: splice\n",
      "Dataset ID: 50, Name: tic-tac-toe\n",
      "Dataset ID: 54, Name: vehicle\n",
      "Dataset ID: 151, Name: electricity\n",
      "Dataset ID: 182, Name: satimage\n",
      "Dataset ID: 188, Name: eucalyptus\n",
      "Dataset ID: 38, Name: sick\n",
      "Dataset ID: 307, Name: vowel\n",
      "Dataset ID: 300, Name: isolet\n",
      "Dataset ID: 458, Name: analcatdata_authorship\n",
      "Dataset ID: 469, Name: analcatdata_dmft\n",
      "Dataset ID: 554, Name: mnist_784\n",
      "Dataset ID: 1049, Name: pc4\n",
      "Dataset ID: 1050, Name: pc3\n",
      "Dataset ID: 1053, Name: jm1\n",
      "Dataset ID: 1063, Name: kc2\n",
      "Dataset ID: 1067, Name: kc1\n",
      "Dataset ID: 1068, Name: pc1\n",
      "Dataset ID: 1590, Name: adult\n",
      "Dataset ID: 4134, Name: Bioresponse\n",
      "Dataset ID: 1510, Name: wdbc\n",
      "Dataset ID: 1489, Name: phoneme\n",
      "Dataset ID: 1494, Name: qsar-biodeg\n",
      "Dataset ID: 1497, Name: wall-robot-navigation\n",
      "Dataset ID: 1501, Name: semeion\n",
      "Dataset ID: 1480, Name: ilpd\n",
      "Dataset ID: 1485, Name: madelon\n",
      "Dataset ID: 1486, Name: nomao\n",
      "Dataset ID: 1487, Name: ozone-level-8hr\n",
      "Dataset ID: 1468, Name: cnae-9\n",
      "Dataset ID: 1475, Name: first-order-theorem-proving\n",
      "Dataset ID: 1462, Name: banknote-authentication\n",
      "Dataset ID: 1464, Name: blood-transfusion-service-center\n",
      "Dataset ID: 4534, Name: PhishingWebsites\n",
      "Dataset ID: 6332, Name: cylinder-bands\n",
      "Dataset ID: 1461, Name: bank-marketing\n",
      "Dataset ID: 4538, Name: GesturePhaseSegmentationProcessed\n",
      "Dataset ID: 1478, Name: har\n",
      "Dataset ID: 23381, Name: dresses-sales\n",
      "Dataset ID: 40499, Name: texture\n",
      "Dataset ID: 40668, Name: connect-4\n",
      "Dataset ID: 40966, Name: MiceProtein\n",
      "Dataset ID: 40982, Name: steel-plates-fault\n",
      "Dataset ID: 40994, Name: climate-model-simulation-crashes\n",
      "Dataset ID: 40983, Name: wilt\n",
      "Dataset ID: 40975, Name: car\n",
      "Dataset ID: 40984, Name: segment\n",
      "Dataset ID: 40979, Name: mfeat-pixel\n",
      "Dataset ID: 40996, Name: Fashion-MNIST\n",
      "Dataset ID: 41027, Name: jungle_chess_2pcs_raw_endgame_complete\n",
      "Dataset ID: 23517, Name: numerai28.6\n",
      "Dataset ID: 40923, Name: Devnagari-Script\n",
      "Dataset ID: 40927, Name: CIFAR_10\n",
      "Dataset ID: 40978, Name: Internet-Advertisements\n",
      "Dataset ID: 40670, Name: dna\n",
      "Dataset ID: 40701, Name: churn\n",
      "\n",
      "Total Number of Datasets: 72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import openml\n",
    "\n",
    "suite = openml.study.get_suite('99')  # Use 'get_suite' to load the benchmark suite\n",
    "\n",
    "print(\"List of Datasets in OpenML-CC18 Curated Classification benchmark:\\n\")\n",
    "dataset_count = 0  # Initialize counter for datasets\n",
    "\n",
    "for task_id in suite.tasks:\n",
    "    task = openml.tasks.get_task(task_id, download_splits=False)\n",
    "    dataset = openml.datasets.get_dataset(task.dataset_id, \n",
    "                                          download_data=True, \n",
    "                                          download_qualities=True, \n",
    "                                          download_features_meta_data=True)\n",
    "    \n",
    "    # Increment the dataset counter\n",
    "    dataset_count += 1\n",
    "\n",
    "    # Print details of each dataset\n",
    "    print(f\"Dataset ID: {dataset.dataset_id}, Name: {dataset.name}\")\n",
    "\n",
    "# Print the total number of datasets after the loop\n",
    "print(f\"\\nTotal Number of Datasets: {dataset_count}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27923a0-6ad9-425d-8290-a7181599a2f6",
   "metadata": {},
   "source": [
    "Instead of evaluating the K-NN on all available datasets, I focused on those specifically tailored to binary classification, with an emphasis on identifying and selecting those with significant class imbalances.\n",
    "\n",
    "To streamline this evaluation, I pre-selected relevant datasets tailored to binary classification from the OpenML-CC18 suite and saved them into a CSV file named **dslist.csv**.\n",
    "\n",
    "After loading the dataset information from dslist.csv, I calculated the **imbalance ratio** for each dataset. This ratio is determined by taking the maximum of (Class A / Class B) and (Class B / Class A). This calculation helped to identify the degree of imbalance present in each dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88234310-1858-4e52-ae46-8d734dbfb122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset: ['DATASET', 'CLASS A', 'CLASS B']\n",
      "                             DATASET  CLASS A  CLASS B  IMBALANCE RATIO\n",
      "1                               wilt   4578.0    261.0        17.540230\n",
      "2                               sick   3541.0    231.0        15.329004\n",
      "3                    ozone-level-8hr   2374.0    160.0        14.837500\n",
      "4                                pc1   1032.0     77.0        13.402597\n",
      "5   climate-model-simulation-crashes     46.0    494.0        10.739130\n",
      "6                                pc3   1403.0    160.0         8.768750\n",
      "7                     bank-marketing  39922.0   5289.0         7.548119\n",
      "8                                pc4   1280.0    178.0         7.191011\n",
      "9             Internet-Advertisement    459.0   2820.0         6.143791\n",
      "10                             churn   4293.0    707.0         6.072136\n",
      "11                               kc1   1783.0    326.0         5.469325\n",
      "12                               jm1   8779.0   2106.0         4.168566\n",
      "13                               kc2    415.0    107.0         3.878505\n",
      "14  blood-transfusion-service-center    570.0    178.0         3.202247\n",
      "15                             adult  11687.0  37155.0         3.179173\n",
      "16                             nomao   9844.0  24621.0         2.501117\n",
      "17                              ilpd    416.0    167.0         2.491018\n",
      "18                           phoneme   3818.0   1586.0         2.407314\n",
      "19                          credit-g    700.0    300.0         2.333333\n",
      "20                       qsar-biodeg    699.0    356.0         1.963483\n",
      "21                          breast-w    458.0    241.0         1.900415\n",
      "22                       tic-tac-toe    332.0    626.0         1.885542\n",
      "23                          diabetes    500.0    268.0         1.865672\n",
      "24                              wdbc    357.0    212.0         1.683962\n",
      "25                          spambase   2788.0   1813.0         1.537783\n",
      "26                     dresses-sales    290.0    210.0         1.380952\n",
      "27                    cylinder-bands    228.0    312.0         1.368421\n",
      "28                       electricity  19273.0  26075.0         1.352929\n",
      "29                  PhishingWebsites   4898.0   6157.0         1.257044\n",
      "30           banknote-authentication    762.0    610.0         1.249180\n",
      "31                   credit-approval    307.0    383.0         1.247557\n",
      "32                       Bioresponse   1717.0   2034.0         1.184624\n",
      "33                          kr-vs-kp   1669.0   1527.0         1.092993\n",
      "34                       numerai28.6  23831.0  24329.0         1.020897\n",
      "35                           madelon   1300.0   1300.0         1.000000\n",
      "0                                NaN      NaN      NaN              NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "data = pd.read_csv('DS/dslist.csv')\n",
    "\n",
    "# Ensure the column names are as expected\n",
    "print(\"Columns in the dataset:\", data.columns.tolist())\n",
    "\n",
    "# Calculate the imbalance ratio as the maximum of (class A / class B) and (class B / class A) to ensure it's >= 1\n",
    "data['IMBALANCE RATIO'] = data.apply(lambda row: max(row['CLASS A'] / row['CLASS B'], row['CLASS B'] / row['CLASS A']), axis=1)\n",
    "\n",
    "# Print the dataset names with their corresponding imbalance ratios, sorted by the imbalance ratio in descending order\n",
    "print(data[['DATASET', 'CLASS A', 'CLASS B', 'IMBALANCE RATIO']].sort_values(by='IMBALANCE RATIO', ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc300ddd-7288-4e70-a3ac-165cb02f3824",
   "metadata": {},
   "source": [
    "Given the challenges posed by class imbalance in binary classification tasks, such as **bias towards the majority class**, I decided to only focus on those datasets where the **imbalance ratio** was **greater than 5**. This was chosen to highlight datasets where K-NN's performance could be more significantly affected by the imbalance. The final list of benchmark datasets that were selected is found below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7579b7ab-fc5c-4e1c-8f9a-553bdda04aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             DATASET  CLASS A  CLASS B  IMBALANCE RATIO\n",
      "1                               wilt   4578.0    261.0        17.540230\n",
      "2                               sick   3541.0    231.0        15.329004\n",
      "3                    ozone-level-8hr   2374.0    160.0        14.837500\n",
      "4                                pc1   1032.0     77.0        13.402597\n",
      "5   climate-model-simulation-crashes     46.0    494.0        10.739130\n",
      "6                                pc3   1403.0    160.0         8.768750\n",
      "7                     bank-marketing  39922.0   5289.0         7.548119\n",
      "8                                pc4   1280.0    178.0         7.191011\n",
      "9             Internet-Advertisement    459.0   2820.0         6.143791\n",
      "10                             churn   4293.0    707.0         6.072136\n",
      "11                               kc1   1783.0    326.0         5.469325\n"
     ]
    }
   ],
   "source": [
    "# Filter datasets where the imbalance ratio is greater than 5\n",
    "filtered_data = data[data['IMBALANCE RATIO'] > 5]\n",
    "\n",
    "# Print the filtered datasets that have an imbalance ratio greater than 5\n",
    "print(filtered_data[['DATASET', 'CLASS A', 'CLASS B', 'IMBALANCE RATIO']].sort_values(by='IMBALANCE RATIO', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faf6b17-32a9-4920-8c7c-f98eea86e5ef",
   "metadata": {},
   "source": [
    "However, after reviewing the computational demands and performance metrics, I also decided to exclude the **bank-marketing** dataset from the current analysis. This particular dataset, due to its substantial size and high number of attributes, posed significant challenges for the K-NN algorithm, resulting in **long processing times**. Given these constraints, removing the dataset was necessary to ensure a more efficient and manageable workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d3c052-3a99-4ea0-bc5e-825329054788",
   "metadata": {},
   "source": [
    "<a id=\"4.2-DS-evaluation\"></a>\n",
    "### 4.2. Datasets Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb0336d-5fc7-4642-8f1a-287e263f4634",
   "metadata": {},
   "source": [
    "To effectively evaluate the **ten** pre-selected datasets, I began by copying the necessary machine learning algorithms from the GitHub repository previously mentioned to the folder \"MLAlgorithms\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90e8e29a-1343-4704-a3e7-f15f240bd284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('MLAlgorithms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceefaaa-8cde-4c49-9c64-0959a1ec4445",
   "metadata": {},
   "source": [
    "Then, I proceeded to import all the necessary libraries required for conducting the evaluations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c1cb416-bd3c-4151-b126-189fefb11d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609bfd2d-6fb2-45b5-a352-967f8f779129",
   "metadata": {},
   "source": [
    "For each dataset, I have implemented a **Stratified 5-Fold Cross-Validation** method to ensure a thorough and unbiased evaluation. Given that some datasets have a small number of examples, a 10-fold cross-validation seemed excessive, even though it was initially considered. This approach maintains the proportion of classes across each fold, which is crucial for datasets with varying class distributions. During the cross-validation process, I recorded the **accuracy**, **precision**, **recall**, and **F1-score** for each fold, saving these metrics in a CSV file within the 'Results' folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5fe6a6-0a1c-4c5c-be11-82e287909159",
   "metadata": {},
   "source": [
    "Before initiating the cross-validation, I individually **preprocessed** each dataset, where preprocessing steps were tailored to the specific characteristics and requirements of each dataset. I also compiled a brief description of the structure of each dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f577d078-662f-483b-91db-9928ec2e06e2",
   "metadata": {},
   "source": [
    "To ensure consistency in the evaluations, especially when comparing a different algorithm variation later, I utilized a **fixed random seed**. This was crucial for replicating the exact splits in the Stratified cross-validation when the same datasets were subjected to the modified version of the algorithm, thus ensuring that any differences in performance metrics were attributable solely to the algorithmic changes and not to variations in the dataset splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6110597d-8283-4a08-8bf6-f0a5469f1362",
   "metadata": {},
   "source": [
    "The following function **loads the datasets arff** to dataframe and is used for each dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f16f67f-d30c-4607-867c-a129491b291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_arff_to_dataframe(file_path):\n",
    "    try:\n",
    "        data, meta = arff.loadarff(file_path)\n",
    "        df = pd.DataFrame(data)\n",
    "        for col in df.select_dtypes([object]):\n",
    "            df[col] = df[col].apply(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data from {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2753666e-2e1c-4ab7-86b4-9ffd7aa9be5a",
   "metadata": {},
   "source": [
    "<a id=\"4.2.1-wilt\"></a>\n",
    "#### 4.2.1. wilt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869f58c3-315f-4a14-8a41-8b0f1f076503",
   "metadata": {},
   "source": [
    "**Relevant aspects**:\n",
    "\n",
    "- Distribution of target variable (\"class\"): \"1\" (4578) / \"2\" (261).\n",
    "\n",
    "- All other attributes are numeric.\n",
    "\n",
    "- No missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c96ff78e-caaa-4a12-b2fe-c42d98a3c3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Results/wilt_first_benchmark.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.961777</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.493151</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.974174</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.557692</td>\n",
       "      <td>0.698795</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.967975</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.442308</td>\n",
       "      <td>0.597403</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.966942</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.974147</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold  Accuracy  Precision    Recall  F1 Score     Classifier\n",
       "0     1  0.961777   0.900000  0.339623  0.493151  KNNClassifier\n",
       "1     2  0.974174   0.935484  0.557692  0.698795  KNNClassifier\n",
       "2     3  0.967975   0.920000  0.442308  0.597403  KNNClassifier\n",
       "3     4  0.966942   0.916667  0.423077  0.578947  KNNClassifier\n",
       "4     5  0.974147   0.965517  0.538462  0.691358  KNNClassifier"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from knn import KNNClassifier\n",
    "\n",
    "# Define parameters for the dataset\n",
    "file_path = 'DS/wilt.arff'\n",
    "df = load_arff_to_dataframe(file_path)\n",
    "target_column = 'class'\n",
    "model = KNNClassifier(k=5)\n",
    "model_name = 'KNNClassifier'\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(df, target_column):\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "    return X, y\n",
    "\n",
    "# Model evaluation\n",
    "def evaluate_model(X, y, model, model_name, n_splits, random_seed=42):\n",
    "    # Stratified 5-Fold cross-validation\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "    results = {\n",
    "        'Fold': [],\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1 Score': []\n",
    "    }\n",
    "    \n",
    "    fold_idx = 1\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Fit the model and make predictions\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Record metrics\n",
    "        results['Fold'].append(fold_idx)\n",
    "        results['Accuracy'].append(accuracy_score(y_test, predictions))\n",
    "        results['Precision'].append(precision_score(y_test, predictions, pos_label='2', average='binary'))\n",
    "        results['Recall'].append(recall_score(y_test, predictions, pos_label='2', average='binary'))\n",
    "        results['F1 Score'].append(f1_score(y_test, predictions, pos_label='2', average='binary'))\n",
    "        \n",
    "        fold_idx += 1\n",
    "    \n",
    "    # Convert results to DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df['Classifier'] = model_name\n",
    "    results_file = f\"Results/wilt_first_benchmark.csv\"\n",
    "    results_df.to_csv(results_file, index=False)\n",
    "    print(f'Results saved to {results_file}')\n",
    "    return results_df\n",
    "\n",
    "# Main function to run the evaluation\n",
    "def run_evaluation(file_path, target_column, model, model_name, n_splits=5):\n",
    "    df = load_arff_to_dataframe(file_path)\n",
    "    X, y = preprocess_data(df, target_column)\n",
    "    results_df = evaluate_model(X, y, model, model_name, n_splits)\n",
    "    return results_df\n",
    "\n",
    "# Run evaluation for the wilt dataset\n",
    "results_df = run_evaluation(file_path, target_column, model, model_name)\n",
    "\n",
    "# Display the results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2a6138-599e-4826-884c-ea232d56736d",
   "metadata": {},
   "source": [
    "<a id=\"4.2.2-sick\"></a>\n",
    "#### 4.2.2. sick"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac8c5a9-2e0f-4c67-9d7f-8bc505c49d3d",
   "metadata": {},
   "source": [
    "**Relevant aspects**:\n",
    "\n",
    "- Distribution of target variable (\"Class\"): \"negative\" (3541) / \"sick\" (231).\n",
    "\n",
    "- Some attributes are nominal, others numeric.\n",
    "\n",
    "- There are some missing values. \n",
    "\n",
    "**Key Changes** (related to data preprocessing):\n",
    "\n",
    "- Handling Missing Values: Implemented imputation for both numeric and categorical features.\n",
    "  \n",
    "- Encoding Nominal Attributes: Used one-hot encoding for categorical features.\n",
    "  \n",
    "- Dropping Columns: Dropped the \"TBG\" column as it contains only missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f017ae4-cdb2-444d-9524-1915e1ec34e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Results/sick_first_benchmark.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.968212</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.972185</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.966844</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.970822</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.968170</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold  Accuracy  Precision    Recall  F1 Score     Classifier\n",
       "0     1  0.968212   0.843750  0.586957  0.692308  KNNClassifier\n",
       "1     2  0.972185   0.964286  0.574468  0.720000  KNNClassifier\n",
       "2     3  0.966844   0.838710  0.565217  0.675325  KNNClassifier\n",
       "3     4  0.970822   0.928571  0.565217  0.702703  KNNClassifier\n",
       "4     5  0.968170   0.843750  0.586957  0.692308  KNNClassifier"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from knn import KNNClassifier\n",
    "\n",
    "# Define parameters for the dataset\n",
    "file_path = 'DS/sick.arff'\n",
    "df = load_arff_to_dataframe(file_path)\n",
    "target_column = 'Class'\n",
    "model = KNNClassifier(k=5)\n",
    "model_name = 'KNNClassifier'\n",
    "\n",
    "def preprocess_data(df, target_column):\n",
    "    # Drop the column 'TBG' as it only contains missing values\n",
    "    df = df.drop(columns=['TBG'])\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column].values\n",
    "    \n",
    "    # Identify numeric and categorical columns\n",
    "    numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_features = X.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    # Create preprocessing pipelines for both numeric and categorical data\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values with mean\n",
    "        ('scaler', StandardScaler())  # Standardize numeric features\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values with most frequent value\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-hot encode categorical features\n",
    "    ])\n",
    "\n",
    "    # Combine preprocessing steps\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Fit and transform the features\n",
    "    X_preprocessed = preprocessor.fit_transform(X)\n",
    "    \n",
    "    return X_preprocessed, y\n",
    "\n",
    "\n",
    "# Model evaluation\n",
    "def evaluate_model(X, y, model, model_name, n_splits, random_seed=42):\n",
    "    # Stratified 5-Fold cross-validation\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "    results = {\n",
    "        'Fold': [],\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1 Score': []\n",
    "    }\n",
    "    \n",
    "    fold_idx = 1\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Fit the model and make predictions\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Record metrics\n",
    "        results['Fold'].append(fold_idx)\n",
    "        results['Accuracy'].append(accuracy_score(y_test, predictions))\n",
    "        results['Precision'].append(precision_score(y_test, predictions, pos_label='sick', average='binary'))\n",
    "        results['Recall'].append(recall_score(y_test, predictions, pos_label='sick', average='binary'))\n",
    "        results['F1 Score'].append(f1_score(y_test, predictions, pos_label='sick', average='binary'))\n",
    "        \n",
    "        fold_idx += 1\n",
    "    \n",
    "    # Convert results to DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df['Classifier'] = model_name\n",
    "    results_file = f\"Results/sick_first_benchmark.csv\"\n",
    "    results_df.to_csv(results_file, index=False)\n",
    "    print(f'Results saved to {results_file}')\n",
    "    return results_df\n",
    "\n",
    "# Main function to run the evaluation\n",
    "def run_evaluation(file_path, target_column, model, model_name, n_splits=5):\n",
    "    df = load_arff_to_dataframe(file_path)\n",
    "    X, y = preprocess_data(df, target_column)\n",
    "    results_df = evaluate_model(X, y, model, model_name, n_splits)\n",
    "    return results_df\n",
    "\n",
    "# Run evaluation for the wilt dataset\n",
    "results_df = run_evaluation(file_path, target_column, model, model_name)\n",
    "\n",
    "# Display the results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a54527-6882-4e4e-a6ef-827ce1fcd198",
   "metadata": {},
   "source": [
    "<a id=\"4.2.3-ozone\"></a>\n",
    "#### 4.2.3. ozone-level-8hr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d58eb08-003a-4d87-bb66-1634b01871f4",
   "metadata": {},
   "source": [
    "**Relevant aspects**:\n",
    "\n",
    "- Distribution of target variable (\"Class\"): \"1\" (2374) / \"2\" (160).\n",
    "\n",
    "- All other attributes are numeric.\n",
    "\n",
    "- No missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1b66525-9e7e-4c00-b4f1-b9d593cf0094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Results/ozone-level-8hr_first_benchmark.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.930966</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.936884</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.930966</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.18750</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.940828</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.936759</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.06250</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold  Accuracy  Precision   Recall  F1 Score     Classifier\n",
       "0     1  0.930966   0.333333  0.09375  0.146341  KNNClassifier\n",
       "1     2  0.936884   0.500000  0.25000  0.333333  KNNClassifier\n",
       "2     3  0.930966   0.400000  0.18750  0.255319  KNNClassifier\n",
       "3     4  0.940828   0.583333  0.21875  0.318182  KNNClassifier\n",
       "4     5  0.936759   0.500000  0.06250  0.111111  KNNClassifier"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from knn import KNNClassifier\n",
    "\n",
    "# Define parameters for the dataset\n",
    "file_path = 'DS/ozone-level-8hr.arff'\n",
    "df = load_arff_to_dataframe(file_path)\n",
    "target_column = 'Class'\n",
    "model = KNNClassifier(k=5)\n",
    "model_name = 'KNNClassifier'\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(df, target_column):\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "    return X, y\n",
    "\n",
    "# Model evaluation\n",
    "def evaluate_model(X, y, model, model_name, n_splits, random_seed=42):\n",
    "    # Stratified 5-Fold cross-validation\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "    results = {\n",
    "        'Fold': [],\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1 Score': []\n",
    "    }\n",
    "    \n",
    "    fold_idx = 1\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Fit the model and make predictions\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Record metrics\n",
    "        results['Fold'].append(fold_idx)\n",
    "        results['Accuracy'].append(accuracy_score(y_test, predictions))\n",
    "        results['Precision'].append(precision_score(y_test, predictions, pos_label='2', average='binary'))\n",
    "        results['Recall'].append(recall_score(y_test, predictions, pos_label='2', average='binary'))\n",
    "        results['F1 Score'].append(f1_score(y_test, predictions, pos_label='2', average='binary'))\n",
    "        \n",
    "        fold_idx += 1\n",
    "    \n",
    "    # Convert results to DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df['Classifier'] = model_name\n",
    "    results_file = \"Results/ozone-level-8hr_first_benchmark.csv\"\n",
    "    results_df.to_csv(results_file, index=False)\n",
    "    print(f'Results saved to {results_file}')\n",
    "    return results_df\n",
    "\n",
    "# Main function to run the evaluation\n",
    "def run_evaluation(file_path, target_column, model, model_name, n_splits=5):\n",
    "    df = load_arff_to_dataframe(file_path)\n",
    "    X, y = preprocess_data(df, target_column)\n",
    "    results_df = evaluate_model(X, y, model, model_name, n_splits)\n",
    "    return results_df\n",
    "\n",
    "# Run evaluation for the wilt dataset\n",
    "results_df = run_evaluation(file_path, target_column, model, model_name)\n",
    "\n",
    "# Display the results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23b6888-92ff-45c4-bc57-2056d4048801",
   "metadata": {},
   "source": [
    "<a id=\"4.2.4-pc1\"></a>\n",
    "#### 4.2.4. pc1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434d4b27-af09-49a8-8188-e5914032c734",
   "metadata": {},
   "source": [
    "**Relevant aspects**:\n",
    "\n",
    "- Distribution of target variable (\"defects\"): \"false\" (1032) / \"true\" (77).\n",
    "\n",
    "- All other attributes are numeric.\n",
    "\n",
    "- No missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "371dca64-3f7a-4d2d-b0f1-3ee3cfab5f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Results/pc1_first_benchmark.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.936937</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.927928</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.914414</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.932432</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.918552</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold  Accuracy  Precision    Recall  F1 Score     Classifier\n",
       "0     1  0.936937   0.571429  0.266667  0.363636  KNNClassifier\n",
       "1     2  0.927928   0.400000  0.133333  0.200000  KNNClassifier\n",
       "2     3  0.914414   0.363636  0.250000  0.296296  KNNClassifier\n",
       "3     4  0.932432   0.600000  0.187500  0.285714  KNNClassifier\n",
       "4     5  0.918552   0.285714  0.133333  0.181818  KNNClassifier"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from knn import KNNClassifier\n",
    "\n",
    "# Define parameters for the dataset\n",
    "file_path = 'DS/pc1.arff'\n",
    "df = load_arff_to_dataframe(file_path)\n",
    "target_column = 'defects'\n",
    "model = KNNClassifier(k=5)\n",
    "model_name = 'KNNClassifier'\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(df, target_column):\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "    return X, y\n",
    "\n",
    "# Model evaluation\n",
    "def evaluate_model(X, y, model, model_name, n_splits, random_seed=42):\n",
    "    # Stratified 5-Fold cross-validation\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "    results = {\n",
    "        'Fold': [],\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1 Score': []\n",
    "    }\n",
    "    \n",
    "    fold_idx = 1\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Fit the model and make predictions\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Record metrics\n",
    "        results['Fold'].append(fold_idx)\n",
    "        results['Accuracy'].append(accuracy_score(y_test, predictions))\n",
    "        results['Precision'].append(precision_score(y_test, predictions, pos_label='true', average='binary'))\n",
    "        results['Recall'].append(recall_score(y_test, predictions, pos_label='true', average='binary'))\n",
    "        results['F1 Score'].append(f1_score(y_test, predictions, pos_label='true', average='binary'))\n",
    "        \n",
    "        fold_idx += 1\n",
    "    \n",
    "    # Convert results to DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df['Classifier'] = model_name\n",
    "    results_file = \"Results/pc1_first_benchmark.csv\"\n",
    "    results_df.to_csv(results_file, index=False)\n",
    "    print(f'Results saved to {results_file}')\n",
    "    return results_df\n",
    "\n",
    "# Main function to run the evaluation\n",
    "def run_evaluation(file_path, target_column, model, model_name, n_splits=5):\n",
    "    df = load_arff_to_dataframe(file_path)\n",
    "    X, y = preprocess_data(df, target_column)\n",
    "    results_df = evaluate_model(X, y, model, model_name, n_splits)\n",
    "    return results_df\n",
    "\n",
    "# Run evaluation for the wilt dataset\n",
    "results_df = run_evaluation(file_path, target_column, model, model_name)\n",
    "\n",
    "# Display the results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18cd602-83ad-40b3-9e8c-89acf9d3dd7c",
   "metadata": {},
   "source": [
    "<a id=\"4.2.5-climate\"></a>\n",
    "#### 4.2.5. climate-model-simulation-crashes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad50bd9-b8db-47f7-8c8b-5ec773e8acd2",
   "metadata": {},
   "source": [
    "**Relevant aspects**:\n",
    "\n",
    "- Distribution of target variable (\"outcome\"): \"0\" (46) / \"1\" (494).\n",
    "\n",
    "- All other attributes are numeric.\n",
    "\n",
    "- No missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae589e1a-04c6-4c2f-8152-bd64fafa57df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Results/climate-model-simulation-crashes_first_benchmark.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.935185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold  Accuracy  Precision    Recall  F1 Score     Classifier\n",
       "0     1  0.916667   0.666667  0.200000  0.307692  KNNClassifier\n",
       "1     2  0.907407   0.000000  0.000000  0.000000  KNNClassifier\n",
       "2     3  0.935185   1.000000  0.222222  0.363636  KNNClassifier\n",
       "3     4  0.916667   0.000000  0.000000  0.000000  KNNClassifier\n",
       "4     5  0.916667   0.500000  0.111111  0.181818  KNNClassifier"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from knn import KNNClassifier\n",
    "\n",
    "# Define parameters for the dataset\n",
    "file_path = 'DS/climate-model-simulation-crashes.arff'\n",
    "df = load_arff_to_dataframe(file_path)\n",
    "target_column = 'outcome'\n",
    "model = KNNClassifier(k=5)\n",
    "model_name = 'KNNClassifier'\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(df, target_column):\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "    return X, y\n",
    "\n",
    "# Model evaluation\n",
    "def evaluate_model(X, y, model, model_name, n_splits, random_seed=42):\n",
    "    # Stratified 5-Fold cross-validation\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "    results = {\n",
    "        'Fold': [],\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1 Score': []\n",
    "    }\n",
    "    \n",
    "    fold_idx = 1\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Fit the model and make predictions\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Record metrics\n",
    "        results['Fold'].append(fold_idx)\n",
    "        results['Accuracy'].append(accuracy_score(y_test, predictions))\n",
    "        results['Precision'].append(precision_score(y_test, predictions, pos_label='0', average='binary', zero_division=0))  \n",
    "        results['Recall'].append(recall_score(y_test, predictions, pos_label='0', average='binary', zero_division=0))  \n",
    "        results['F1 Score'].append(f1_score(y_test, predictions, pos_label='0', average='binary', zero_division=0))  \n",
    "        \n",
    "        fold_idx += 1\n",
    "    \n",
    "    # Convert results to DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df['Classifier'] = model_name\n",
    "    results_file = \"Results/climate-model-simulation-crashes_first_benchmark.csv\"\n",
    "    results_df.to_csv(results_file, index=False)\n",
    "    print(f'Results saved to {results_file}')\n",
    "    return results_df\n",
    "\n",
    "# Main function to run the evaluation\n",
    "def run_evaluation(file_path, target_column, model, model_name, n_splits=5):\n",
    "    df = load_arff_to_dataframe(file_path)\n",
    "    X, y = preprocess_data(df, target_column)\n",
    "    results_df = evaluate_model(X, y, model, model_name, n_splits)\n",
    "    return results_df\n",
    "\n",
    "# Run evaluation for the wilt dataset\n",
    "results_df = run_evaluation(file_path, target_column, model, model_name)\n",
    "\n",
    "# Display the results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda91300-8d4c-446e-8811-52111f92e6e9",
   "metadata": {},
   "source": [
    "<a id=\"4.2.6-pc3\"></a>\n",
    "#### 4.2.6. pc3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9286fa-f911-46ef-b56e-22022a243783",
   "metadata": {},
   "source": [
    "**Relevant aspects**:\n",
    "\n",
    "- Distribution of target variable (\"c\"): \"FALSE\" (1403) / \"TRUE\" (160).\n",
    "\n",
    "- All other attributes are numeric.\n",
    "\n",
    "- No missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78b6cb64-0889-4d5a-a982-ba83426fa2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Results/pc3_first_benchmark.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.900958</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.18750</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.891374</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.18750</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.884984</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.18750</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.878205</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.06250</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.881410</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold  Accuracy  Precision   Recall  F1 Score     Classifier\n",
       "0     1  0.900958   0.545455  0.18750  0.279070  KNNClassifier\n",
       "1     2  0.891374   0.428571  0.18750  0.260870  KNNClassifier\n",
       "2     3  0.884984   0.375000  0.18750  0.250000  KNNClassifier\n",
       "3     4  0.878205   0.200000  0.06250  0.095238  KNNClassifier\n",
       "4     5  0.881410   0.272727  0.09375  0.139535  KNNClassifier"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from knn import KNNClassifier\n",
    "\n",
    "# Define parameters for the dataset\n",
    "file_path = 'DS/pc3.arff'\n",
    "df = load_arff_to_dataframe(file_path)\n",
    "target_column = 'c'\n",
    "model = KNNClassifier(k=5)\n",
    "model_name = 'KNNClassifier'\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(df, target_column):\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "    return X, y\n",
    "\n",
    "# Model evaluation\n",
    "def evaluate_model(X, y, model, model_name, n_splits, random_seed=42):\n",
    "    # Stratified 5-Fold cross-validation\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "    results = {\n",
    "        'Fold': [],\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1 Score': []\n",
    "    }\n",
    "    \n",
    "    fold_idx = 1\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Fit the model and make predictions\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Record metrics\n",
    "        results['Fold'].append(fold_idx)\n",
    "        results['Accuracy'].append(accuracy_score(y_test, predictions))\n",
    "        results['Precision'].append(precision_score(y_test, predictions, pos_label='TRUE', average='binary'))\n",
    "        results['Recall'].append(recall_score(y_test, predictions, pos_label='TRUE', average='binary'))\n",
    "        results['F1 Score'].append(f1_score(y_test, predictions, pos_label='TRUE', average='binary'))\n",
    "        \n",
    "        fold_idx += 1\n",
    "    \n",
    "    # Convert results to DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df['Classifier'] = model_name\n",
    "    results_file = \"Results/pc3_first_benchmark.csv\"\n",
    "    results_df.to_csv(results_file, index=False)\n",
    "    print(f'Results saved to {results_file}')\n",
    "    return results_df\n",
    "\n",
    "# Main function to run the evaluation\n",
    "def run_evaluation(file_path, target_column, model, model_name, n_splits=5):\n",
    "    df = load_arff_to_dataframe(file_path)\n",
    "    X, y = preprocess_data(df, target_column)\n",
    "    results_df = evaluate_model(X, y, model, model_name, n_splits)\n",
    "    return results_df\n",
    "\n",
    "# Run evaluation for the wilt dataset\n",
    "results_df = run_evaluation(file_path, target_column, model, model_name)\n",
    "\n",
    "# Display the results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4c2edd-d939-4964-935b-4a4b18ce0169",
   "metadata": {},
   "source": [
    "<a id=\"4.2.7-pc4\"></a>\n",
    "#### 4.2.7. pc4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b91699-8f1f-421a-a95e-30399c22c382",
   "metadata": {},
   "source": [
    "**Relevant aspects**:\n",
    "\n",
    "- Distribution of target variable (\"c\"): \"FALSE\" (1280) / \"TRUE\" (178).\n",
    "\n",
    "- All other attributes are numeric.\n",
    "\n",
    "- No missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ccb29cf5-daf4-4280-a9e2-00ccd79b065e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Results/pc4_first_benchmark.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.880137</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.876712</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.893836</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.883162</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.914089</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold  Accuracy  Precision    Recall  F1 Score     Classifier\n",
       "0     1  0.880137   0.526316  0.277778  0.363636  KNNClassifier\n",
       "1     2  0.876712   0.500000  0.361111  0.419355  KNNClassifier\n",
       "2     3  0.893836   0.619048  0.361111  0.456140  KNNClassifier\n",
       "3     4  0.883162   0.526316  0.285714  0.370370  KNNClassifier\n",
       "4     5  0.914089   0.727273  0.457143  0.561404  KNNClassifier"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from knn import KNNClassifier\n",
    "\n",
    "# Define parameters for the dataset\n",
    "file_path = 'DS/pc4.arff'\n",
    "df = load_arff_to_dataframe(file_path)\n",
    "target_column = 'c'\n",
    "model = KNNClassifier(k=5)\n",
    "model_name = 'KNNClassifier'\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(df, target_column):\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "    return X, y\n",
    "\n",
    "# Model evaluation\n",
    "def evaluate_model(X, y, model, model_name, n_splits, random_seed=42):\n",
    "    # Stratified 5-Fold cross-validation\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "    results = {\n",
    "        'Fold': [],\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1 Score': []\n",
    "    }\n",
    "    \n",
    "    fold_idx = 1\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Fit the model and make predictions\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Record metrics\n",
    "        results['Fold'].append(fold_idx)\n",
    "        results['Accuracy'].append(accuracy_score(y_test, predictions))\n",
    "        results['Precision'].append(precision_score(y_test, predictions, pos_label='TRUE', average='binary'))\n",
    "        results['Recall'].append(recall_score(y_test, predictions, pos_label='TRUE', average='binary'))\n",
    "        results['F1 Score'].append(f1_score(y_test, predictions, pos_label='TRUE', average='binary'))\n",
    "        \n",
    "        fold_idx += 1\n",
    "    \n",
    "    # Convert results to DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df['Classifier'] = model_name\n",
    "    results_file = \"Results/pc4_first_benchmark.csv\"\n",
    "    results_df.to_csv(results_file, index=False)\n",
    "    print(f'Results saved to {results_file}')\n",
    "    return results_df\n",
    "\n",
    "# Main function to run the evaluation\n",
    "def run_evaluation(file_path, target_column, model, model_name, n_splits=5):\n",
    "    df = load_arff_to_dataframe(file_path)\n",
    "    X, y = preprocess_data(df, target_column)\n",
    "    results_df = evaluate_model(X, y, model, model_name, n_splits)\n",
    "    return results_df\n",
    "\n",
    "# Run evaluation for the wilt dataset\n",
    "results_df = run_evaluation(file_path, target_column, model, model_name)\n",
    "\n",
    "# Display the results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51de8fd5-1cd1-4353-a7e8-176dd25d6238",
   "metadata": {},
   "source": [
    "<a id=\"4.2.8-internet\"></a>\n",
    "#### 4.2.8. Internet-Advertisements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5fdc43-cb38-4431-8d9f-9d055ab8dada",
   "metadata": {},
   "source": [
    "**Relevant aspects**:\n",
    "\n",
    "- Distribution of target variable (\"class\"): \"ad\" (459) / \"noad\" (2820).\n",
    "\n",
    "- All other attributes are nominal (\"0\" or \"1\").\n",
    "\n",
    "- No missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ddcff27-902b-4bc8-986a-fad7cc23de07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Results/Internet-Advertisements_first_benchmark.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.946646</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.961890</td>\n",
       "      <td>0.924051</td>\n",
       "      <td>0.793478</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.949695</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.789809</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.954268</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.961832</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold  Accuracy  Precision    Recall  F1 Score     Classifier\n",
       "0     1  0.946646   0.952381  0.652174  0.774194  KNNClassifier\n",
       "1     2  0.961890   0.924051  0.793478  0.853801  KNNClassifier\n",
       "2     3  0.949695   0.953846  0.673913  0.789809  KNNClassifier\n",
       "3     4  0.954268   0.918919  0.739130  0.819277  KNNClassifier\n",
       "4     5  0.961832   0.945946  0.769231  0.848485  KNNClassifier"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from knn import KNNClassifier\n",
    "\n",
    "# Define parameters for the dataset\n",
    "file_path = 'DS/Internet-Advertisements.arff'\n",
    "df = load_arff_to_dataframe(file_path)\n",
    "target_column = 'class'\n",
    "model = KNNClassifier(k=5)\n",
    "model_name = 'KNNClassifier'\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(df, target_column):\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "    return X, y\n",
    "\n",
    "# Model evaluation\n",
    "def evaluate_model(X, y, model, model_name, n_splits, random_seed=42):\n",
    "    # Stratified 5-Fold cross-validation\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "    results = {\n",
    "        'Fold': [],\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1 Score': []\n",
    "    }\n",
    "    \n",
    "    fold_idx = 1\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Fit the model and make predictions\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Record metrics\n",
    "        results['Fold'].append(fold_idx)\n",
    "        results['Accuracy'].append(accuracy_score(y_test, predictions))\n",
    "        results['Precision'].append(precision_score(y_test, predictions, pos_label='ad', average='binary'))\n",
    "        results['Recall'].append(recall_score(y_test, predictions, pos_label='ad', average='binary'))\n",
    "        results['F1 Score'].append(f1_score(y_test, predictions, pos_label='ad', average='binary'))\n",
    "        \n",
    "        fold_idx += 1\n",
    "    \n",
    "    # Convert results to DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df['Classifier'] = model_name\n",
    "    results_file = \"Results/Internet-Advertisements_first_benchmark.csv\"\n",
    "    results_df.to_csv(results_file, index=False)\n",
    "    print(f'Results saved to {results_file}')\n",
    "    return results_df\n",
    "\n",
    "# Main function to run the evaluation\n",
    "def run_evaluation(file_path, target_column, model, model_name, n_splits=5):\n",
    "    df = load_arff_to_dataframe(file_path)\n",
    "    X, y = preprocess_data(df, target_column)\n",
    "    results_df = evaluate_model(X, y, model, model_name, n_splits)\n",
    "    return results_df\n",
    "\n",
    "# Run evaluation for the wilt dataset\n",
    "results_df = run_evaluation(file_path, target_column, model, model_name)\n",
    "\n",
    "# Display the results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac07d788-aadf-4d8b-b3f5-f80eb6ef8ae0",
   "metadata": {},
   "source": [
    "<a id=\"4.2.9-churn\"></a>\n",
    "#### 4.2.9. churn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5bee9f-b236-4067-8dd5-92325172efbe",
   "metadata": {},
   "source": [
    "**Relevant aspects**:\n",
    "\n",
    "- Distribution of target variable (\"class\"): \"0\" (4293) / \"1\" (707).\n",
    "\n",
    "- Most attributes are numeric, but some are nominal.\n",
    "\n",
    "- No missing values.\n",
    "\n",
    "**Key Changes** (related to data preprocessing):\n",
    "\n",
    "- Handle Numeric and Nominal Attributes: The ColumnTransformer is used to apply different preprocessing steps to numeric and categorical columns.\n",
    "\n",
    "- One-Hot Encoding: Categorical features are one-hot encoded.\n",
    "\n",
    "- Standardization: Numeric features are standardized using StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46b2dcc0-b927-44cf-8ea3-8e5b82c9e5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Results/churn_first_benchmark.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.156028</td>\n",
       "      <td>0.260355</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.234043</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.234043</td>\n",
       "      <td>0.377143</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.197183</td>\n",
       "      <td>0.316384</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.211268</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold  Accuracy  Precision    Recall  F1 Score     Classifier\n",
       "0     1     0.875   0.785714  0.156028  0.260355  KNNClassifier\n",
       "1     2     0.886   0.846154  0.234043  0.366667  KNNClassifier\n",
       "2     3     0.891   0.970588  0.234043  0.377143  KNNClassifier\n",
       "3     4     0.879   0.800000  0.197183  0.316384  KNNClassifier\n",
       "4     5     0.885   0.909091  0.211268  0.342857  KNNClassifier"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from knn import KNNClassifier\n",
    "\n",
    "# Define parameters for the dataset\n",
    "file_path = 'DS/churn.arff'\n",
    "df = load_arff_to_dataframe(file_path)\n",
    "target_column = 'class'\n",
    "model = KNNClassifier(k=5)\n",
    "model_name = 'KNNClassifier'\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(df, target_column):\n",
    "    # Separate features and target\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column].values\n",
    "    \n",
    "    # Identify numeric and categorical columns\n",
    "    numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_features = X.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    # Create preprocessing pipelines for both numeric and categorical data\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler())  # Standardize numeric features\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-hot encode categorical features\n",
    "    ])\n",
    "\n",
    "    # Combine preprocessing steps\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Fit and transform the features\n",
    "    X_preprocessed = preprocessor.fit_transform(X)\n",
    "    \n",
    "    return X_preprocessed, y\n",
    "\n",
    "# Model evaluation\n",
    "def evaluate_model(X, y, model, model_name, n_splits, random_seed=42):\n",
    "    # Stratified 5-Fold cross-validation\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "    results = {\n",
    "        'Fold': [],\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1 Score': []\n",
    "    }\n",
    "    \n",
    "    fold_idx = 1\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Fit the model and make predictions\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Record metrics\n",
    "        results['Fold'].append(fold_idx)\n",
    "        results['Accuracy'].append(accuracy_score(y_test, predictions))\n",
    "        results['Precision'].append(precision_score(y_test, predictions, pos_label='1', average='binary'))\n",
    "        results['Recall'].append(recall_score(y_test, predictions, pos_label='1', average='binary'))\n",
    "        results['F1 Score'].append(f1_score(y_test, predictions, pos_label='1', average='binary'))\n",
    "        \n",
    "        fold_idx += 1\n",
    "    \n",
    "    # Convert results to DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df['Classifier'] = model_name\n",
    "    results_file = \"Results/churn_first_benchmark.csv\"\n",
    "    results_df.to_csv(results_file, index=False)\n",
    "    print(f'Results saved to {results_file}')\n",
    "    return results_df\n",
    "\n",
    "# Main function to run the evaluation\n",
    "def run_evaluation(file_path, target_column, model, model_name, n_splits=5):\n",
    "    df = load_arff_to_dataframe(file_path)\n",
    "    X, y = preprocess_data(df, target_column)\n",
    "    results_df = evaluate_model(X, y, model, model_name, n_splits)\n",
    "    return results_df\n",
    "\n",
    "# Run evaluation for the wilt dataset\n",
    "results_df = run_evaluation(file_path, target_column, model, model_name)\n",
    "\n",
    "# Display the results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a664abd-833a-4098-8be3-989cad49ee5c",
   "metadata": {},
   "source": [
    "<a id=\"4.2.10-kc1\"></a>\n",
    "#### 4.2.10. kc1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8108ff41-7337-4fed-b18f-596211afce16",
   "metadata": {},
   "source": [
    "**Relevant aspects**:\n",
    "\n",
    "- Distribution of target variable (\"defects\"): \"false\" (1783) / \"true\" (326).\n",
    "\n",
    "- All other attributes are numeric.\n",
    "\n",
    "- No missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49ce2b75-48c2-401d-99b6-7edaf73de1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Results/kc1_first_benchmark.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.812796</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.215385</td>\n",
       "      <td>0.261682</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.812796</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.169231</td>\n",
       "      <td>0.217822</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.819905</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.824645</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.378788</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.845606</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>0.329897</td>\n",
       "      <td>KNNClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold  Accuracy  Precision    Recall  F1 Score     Classifier\n",
       "0     1  0.812796   0.333333  0.215385  0.261682  KNNClassifier\n",
       "1     2  0.812796   0.305556  0.169231  0.217822  KNNClassifier\n",
       "2     3  0.819905   0.387755  0.292308  0.333333  KNNClassifier\n",
       "3     4  0.824645   0.431034  0.378788  0.403226  KNNClassifier\n",
       "4     5  0.845606   0.500000  0.246154  0.329897  KNNClassifier"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from knn import KNNClassifier\n",
    "\n",
    "# Define parameters for the dataset\n",
    "file_path = 'DS/kc1.arff'\n",
    "df = load_arff_to_dataframe(file_path)\n",
    "target_column = 'defects'\n",
    "model = KNNClassifier(k=5)\n",
    "model_name = 'KNNClassifier'\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(df, target_column):\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "    return X, y\n",
    "\n",
    "# Model evaluation\n",
    "def evaluate_model(X, y, model, model_name, n_splits, random_seed=42):\n",
    "    # Stratified 5-Fold cross-validation\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "    results = {\n",
    "        'Fold': [],\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1 Score': []\n",
    "    }\n",
    "    \n",
    "    fold_idx = 1\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Fit the model and make predictions\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Record metrics\n",
    "        results['Fold'].append(fold_idx)\n",
    "        results['Accuracy'].append(accuracy_score(y_test, predictions))\n",
    "        results['Precision'].append(precision_score(y_test, predictions, pos_label='true', average='binary'))\n",
    "        results['Recall'].append(recall_score(y_test, predictions, pos_label='true', average='binary'))\n",
    "        results['F1 Score'].append(f1_score(y_test, predictions, pos_label='true', average='binary'))\n",
    "        \n",
    "        fold_idx += 1\n",
    "    \n",
    "    # Convert results to DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df['Classifier'] = model_name\n",
    "    results_file = \"Results/kc1_first_benchmark.csv\"\n",
    "    results_df.to_csv(results_file, index=False)\n",
    "    print(f'Results saved to {results_file}')\n",
    "    return results_df\n",
    "\n",
    "# Main function to run the evaluation\n",
    "def run_evaluation(file_path, target_column, model, model_name, n_splits=5):\n",
    "    df = load_arff_to_dataframe(file_path)\n",
    "    X, y = preprocess_data(df, target_column)\n",
    "    results_df = evaluate_model(X, y, model, model_name, n_splits)\n",
    "    return results_df\n",
    "\n",
    "# Run evaluation for the wilt dataset\n",
    "results_df = run_evaluation(file_path, target_column, model, model_name)\n",
    "\n",
    "# Display the results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f1e309-f0f6-4b61-acdc-a85d842b4b59",
   "metadata": {},
   "source": [
    "<a id=\"4.3-Results\"></a>\n",
    "### 4.3. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dcf144-7ed2-49b7-8145-3dd64fa0e9e9",
   "metadata": {},
   "source": [
    "After evaluating each dataset individually, I created a script that iterates over the CSV files and analyzes the results. The script reads each .csv file in the Results folder, calculates the **mean** and **standard deviation** for **accuracy**, **precision**, **recall**, and **F1 score**. It compiles these statistics into a summary DataFrame, providing a comprehensive overview of the model's performance across all datasets. The summary is then saved to a new CSV file named **summary_first_analysis.csv** for easy reference and further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faf69036-ca8f-41e0-ac35-c9d2b9c6b596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary analysis saved to Results/summary_first_analysis.csv\n",
      "                            Dataset  Mean Accuracy  Std Accuracy  \\\n",
      "0           Internet-Advertisements       0.954866      0.006938   \n",
      "1                             churn       0.883200      0.006261   \n",
      "2  climate-model-simulation-crashes       0.918519      0.010143   \n",
      "3                               kc1       0.823150      0.013522   \n",
      "4                   ozone-level-8hr       0.935281      0.004265   \n",
      "5                               pc1       0.926053      0.009413   \n",
      "6                               pc3       0.887386      0.009026   \n",
      "7                               pc4       0.889587      0.015123   \n",
      "8                              sick       0.969247      0.002187   \n",
      "9                              wilt       0.969003      0.005261   \n",
      "\n",
      "   Mean Precision  Std Precision  Mean Recall  Std Recall  Mean F1 Score  \\\n",
      "0        0.939029       0.016389     0.725585    0.060739       0.817113   \n",
      "1        0.862309       0.077335     0.206513    0.032304       0.332681   \n",
      "2        0.433333       0.434613     0.106667    0.105877       0.170629   \n",
      "3        0.391536       0.077652     0.260373    0.079961       0.309192   \n",
      "4        0.463333       0.097468     0.162500    0.080889       0.232857   \n",
      "5        0.444156       0.136035     0.194167    0.062888       0.265493   \n",
      "6        0.364351       0.134576     0.143750    0.060917       0.204942   \n",
      "7        0.579790       0.094045     0.348571    0.072569       0.434181   \n",
      "8        0.883813       0.058574     0.575763    0.010894       0.696529   \n",
      "9        0.927534       0.024693     0.460232    0.089256       0.611931   \n",
      "\n",
      "   Std F1 Score  \n",
      "0      0.035080  \n",
      "1      0.046723  \n",
      "2      0.169109  \n",
      "3      0.071518  \n",
      "4      0.100234  \n",
      "5      0.074634  \n",
      "6      0.082107  \n",
      "7      0.080523  \n",
      "8      0.016388  \n",
      "9      0.085530  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Function to analyze a single results CSV file\n",
    "def analyze_results(file_path, benchmark):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Calculate mean and standard deviation for each metric\n",
    "    summary = {\n",
    "        'Dataset': os.path.basename(file_path).replace(f'_{benchmark}_benchmark.csv', ''),\n",
    "        'Mean Accuracy': df['Accuracy'].mean(),\n",
    "        'Std Accuracy': df['Accuracy'].std(),\n",
    "        'Mean Precision': df['Precision'].mean(),\n",
    "        'Std Precision': df['Precision'].std(),\n",
    "        'Mean Recall': df['Recall'].mean(),\n",
    "        'Std Recall': df['Recall'].std(),\n",
    "        'Mean F1 Score': df['F1 Score'].mean(),\n",
    "        'Std F1 Score': df['F1 Score'].std()\n",
    "    }\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Main function to analyze all results\n",
    "def analyze_all_results(results_folder, benchmark):\n",
    "    results_files = glob.glob(os.path.join(results_folder, f'*_{benchmark}_benchmark.csv'))\n",
    "    analysis_results = []\n",
    "\n",
    "    for file_path in results_files:\n",
    "        summary = analyze_results(file_path, benchmark)\n",
    "        analysis_results.append(summary)\n",
    "\n",
    "    # Create a summary DataFrame\n",
    "    summary_df = pd.DataFrame(analysis_results)\n",
    "    summary_df = summary_df[['Dataset', 'Mean Accuracy', 'Std Accuracy', 'Mean Precision', 'Std Precision', 'Mean Recall', 'Std Recall', 'Mean F1 Score', 'Std F1 Score']]\n",
    "    \n",
    "    # Sort the summary DataFrame by Dataset name\n",
    "    summary_df = summary_df.sort_values(by='Dataset').reset_index(drop=True)\n",
    "    \n",
    "    # Save the summary DataFrame to a CSV file\n",
    "    summary_file = os.path.join(results_folder, f'summary_{benchmark}_analysis.csv')\n",
    "    summary_df.to_csv(summary_file, index=False)\n",
    "    print(f'Summary analysis saved to {summary_file}')\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "# Define the results folder and benchmark type\n",
    "results_folder = 'Results'\n",
    "benchmark = 'first'  # Specify the benchmark type as 'first'\n",
    "\n",
    "# Run the analysis\n",
    "summary_df = analyze_all_results(results_folder, benchmark)\n",
    "\n",
    "# Display the summary DataFrame\n",
    "print(summary_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662bf56e-5ac5-4e3e-84ea-4ba7223809c5",
   "metadata": {},
   "source": [
    "As expected with **imbalanced** binary datasets, there is a notable disparity between accuracy and other performance metrics such as precision, recall, and F1 score.\n",
    "\n",
    "**Key notes**:\n",
    "\n",
    "- The accuracy scores across datasets are generally high, ranging from 82% to 97%, which can be misleading.\n",
    "\n",
    "- Despite high accuracy, the precision, recall, and F1 score are significantly lower in many datasets. For example, the pc1 dataset has an accuracy of 92.61%, but much lower precision (44.42%), recall (19.42%), and F1 score (26.55%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8846c19c-22e8-4430-9611-bd9d044b42a7",
   "metadata": {},
   "source": [
    "<a id=\"5-KNN-variant-proposal\"></a>\n",
    "## 5. K-NN's variant proposal and implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556c91a4-62e7-4bcb-a967-cc2b44ae7735",
   "metadata": {},
   "source": [
    "In an effort to address the challenges associated with **class imbalance in binary classification problems**, some modifications were made to the original algorithm. These changes were implemented in a new version of the algorithm (in a file titled **knn2.py**, located in the 'MLAlgorithms' folder). The modifications involved adaptations to the original KNNClassifier, now renamed **KNNVariant**, derived from an adjusted base class KNNBase(BaseEstimator). The primary adjustments focus on dynamic neighbor selection, enhanced influence through distance weighting, and the incorporation of distance thresholds to better manage data imbalance. Hereâs an expanded comparison between the original KNNClassifier and the revised KNNVariant:\n",
    "\n",
    "**Dynamic k-Value**:\n",
    "- Original: The original classifier uses a static k, defined during initialization, which does not change regardless of the data distribution or any local variations within the dataset.\n",
    "- Variant: In contrast, the KNNVariant adjusts k dynamically. The adjustment is based on the average distance of the nearest neighbors:\n",
    "    - If the average distance exceeds an upper threshold (set at the 75th percentile of all pairwise distances in the training data), k is increased but does not surpass max_k.\n",
    "    - If the average distance falls below a lower threshold (set at the 25th percentile), k is decreased to no less than min_k.\n",
    " \n",
    "**Threshold Calculation**\n",
    "- Original: The concept of dynamically adjusting thresholds based on training data distances does not exist in the original model.\n",
    "- Variant: The KNNVariant computes these thresholds during the fitting process. It uses the 75th and 25th percentiles of distances as upper and lower thresholds, respectively. These thresholds serve as benchmarks to dynamically adjust k, enhancing the modelâs responsiveness to varying data distributions.\n",
    "\n",
    "**Distance Weighting**:\n",
    "- Original: The original method considers only the nearest k neighbors for voting, with each neighbor contributing equally to the decision, irrespective of their distance from the query point.\n",
    "- Variant: The KNNVariant introduces an option to weight the influence of each neighbor by the inverse of their distance (1/dist). This weighting scheme prioritizes closer neighbors, allowing for a more nuanced decision-making process that reflects the immediate data structure around the query point.\n",
    "\n",
    "**Aggregation Method**\n",
    "- Original: Typically employs a straightforward majority voting system among the chosen k neighbors to classify a new instance.\n",
    "-Variant: Provides flexibility by supporting both weighted and unweighted aggregation methods. If weight_distance is set to True, the votes are weighted by the inverse distances, promoting decisions that are more reflective of closer and potentially more relevant neighbors. This can be particularly advantageous in scenarios where minority classes are at risk of being overshadowed by more distant majority class neighbors.\n",
    "\n",
    "These enhancements in the KNNVariant were designed to **improve** the classifier's performance on datasets with imbalanced classes by making the classification decision more sensitive to the local structure of the data and **reducing the bias** towards the majority class. The use of dynamic k values and distance-based weighting in the KNNVariant aims to boost precision, recall, and the F1 score, making it a potentially more robust choice for challenging classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0332433-ddb7-4f00-b752-cd4155ea2bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import itertools\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# class BaseEstimator remains the same\n",
    "\n",
    "class KNNBase(BaseEstimator):\n",
    "    def __init__(self, k=5, max_k=9, min_k=3, distance_func=euclidean, weight_distance=True):\n",
    "        \"\"\"\n",
    "        Base class for K Nearest Neighbors classifier with dynamic k\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.max_k = max_k\n",
    "        self.min_k = min_k\n",
    "        self.distance_func = distance_func\n",
    "        self.weight_distance = weight_distance\n",
    "        self.upper_threshold = None\n",
    "        self.lower_threshold = None\n",
    "\n",
    "    def aggregate(self, neighbors_targets, neighbors_weights=None):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _predict(self, X=None):\n",
    "        predictions = [self._predict_x(x) for x in X]\n",
    "\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        super()._setup_input(X, y)\n",
    "        # Calculate distance thresholds based on training data\n",
    "        self._calculate_thresholds()\n",
    "\n",
    "    def _calculate_thresholds(self):\n",
    "        # Calculate distances between all pairs in training data\n",
    "        distances = [self.distance_func(x, y) for x, y in itertools.combinations(self.X, 2)]\n",
    "        distances = np.array(distances)\n",
    "        self.upper_threshold = np.percentile(distances, 75)  # 75th percentile\n",
    "        self.lower_threshold = np.percentile(distances, 25)  # 25th percentile\n",
    "\n",
    "    def _predict_x(self, x):\n",
    "        distances = np.array([self.distance_func(x, example) for example in self.X])\n",
    "        sorted_neighbors = sorted(((dist, target) for (dist, target) in zip(distances, self.y)), key=lambda x: x[0])\n",
    "\n",
    "        dynamic_k = self.k\n",
    "        neighbors_targets = []\n",
    "        neighbors_weights = []\n",
    "\n",
    "        while True:\n",
    "            avg_distance = np.mean([dist for (dist, _) in sorted_neighbors[:dynamic_k]])\n",
    "            if avg_distance > self.upper_threshold and dynamic_k < self.max_k:\n",
    "                dynamic_k = min(self.max_k, dynamic_k + 2)\n",
    "            elif avg_distance < self.lower_threshold and dynamic_k > self.min_k:\n",
    "                dynamic_k = max(self.min_k, dynamic_k - 2)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        neighbors_targets = [target for (_, target) in sorted_neighbors[:dynamic_k]]\n",
    "        neighbors_weights = [1/dist if dist != 0 else 1e-5 for (dist, _) in sorted_neighbors[:dynamic_k]]\n",
    "\n",
    "        return self.aggregate(neighbors_targets, neighbors_weights if self.weight_distance else None)\n",
    "        \n",
    "\n",
    "class KNNVariant(KNNBase):\n",
    "    \"\"\"\n",
    "    Nearest neighbors classifier.\n",
    "\n",
    "    Note: if there is a tie for the most common label among the neighbors, then\n",
    "    the predicted label is arbitrary. This class extends KNNBase and implements\n",
    "    the aggregate method for making predictions based on neighbor voting.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k=5, max_k=10, min_k=3, distance_func=euclidean, weight_distance=True):\n",
    "        \"\"\"\n",
    "        Initialize the KNNVariant with the same parameters as KNNBase,\n",
    "        ensuring all are passed correctly.\n",
    "        \"\"\"\n",
    "        super().__init__(k=k, max_k=max_k, min_k=min_k, distance_func=distance_func, weight_distance=weight_distance)\n",
    "\n",
    "    def aggregate(self, neighbors_targets, neighbors_weights=None):\n",
    "        \"\"\"\n",
    "        Return the most common target label, considering weights if provided.\n",
    "        \"\"\"\n",
    "        if neighbors_weights:\n",
    "            weighted_vote = Counter()\n",
    "            for label, weight in zip(neighbors_targets, neighbors_weights):\n",
    "                weighted_vote[label] += weight\n",
    "            most_common_label = weighted_vote.most_common(1)[0][0]\n",
    "        else:\n",
    "            most_common_label = Counter(neighbors_targets).most_common(1)[0][0]\n",
    "        return most_common_label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd820276-0602-481f-a9cc-2e345753b888",
   "metadata": {},
   "source": [
    "<a id=\"6-Benchmark-second-evaluation\"></a>\n",
    "## 6. Benchmark Second Evaluation\n",
    "\n",
    "<a id=\"6.1-DS-evaluation\"></a>\n",
    "### 6.1. Datasets Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f85d45-80ce-421f-957d-3adbb4082b2c",
   "metadata": {},
   "source": [
    "The same process of evaluation, previously explained in the First Benchmark Evaluation, was applied to all datasets, but now using the **KNNVariant** included in **knn2.py**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1b9a7d-7dbf-4f97-9eb6-9fb818b232ff",
   "metadata": {},
   "source": [
    "<a id=\"6.1.1-wilt\"></a>\n",
    "#### 6.1.1. wilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eb42809-1ac9-42aa-a25a-e5b8b0979e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Results/wilt_second_benchmark.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.962810</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.974174</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>0.712644</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.970041</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.970041</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.641975</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.977249</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold  Accuracy  Precision    Recall  F1 Score  Classifier\n",
       "0     1  0.962810   0.793103  0.433962  0.560976  KNNVariant\n",
       "1     2  0.974174   0.885714  0.596154  0.712644  KNNVariant\n",
       "2     3  0.970041   0.870968  0.519231  0.650602  KNNVariant\n",
       "3     4  0.970041   0.896552  0.500000  0.641975  KNNVariant\n",
       "4     5  0.977249   0.968750  0.596154  0.738095  KNNVariant"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from knn2 import KNNVariant\n",
    "\n",
    "# Define parameters for the dataset\n",
    "file_path = 'DS/wilt.arff'\n",
    "df = load_arff_to_dataframe(file_path)\n",
    "target_column = 'class'\n",
    "model = KNNVariant(k=5, max_k=9, min_k=3, weight_distance=True)\n",
    "model_name = 'KNNVariant'\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(df, target_column):\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "    return X, y\n",
    "\n",
    "# Model evaluation\n",
    "def evaluate_model(X, y, model, model_name, n_splits, random_seed=42):\n",
    "    # Stratified 5-Fold cross-validation\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "    results = {\n",
    "        'Fold': [],\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1 Score': []\n",
    "    }\n",
    "    \n",
    "    fold_idx = 1\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Fit the model and make predictions\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Record metrics\n",
    "        results['Fold'].append(fold_idx)\n",
    "        results['Accuracy'].append(accuracy_score(y_test, predictions))\n",
    "        results['Precision'].append(precision_score(y_test, predictions, pos_label='2', average='binary'))\n",
    "        results['Recall'].append(recall_score(y_test, predictions, pos_label='2', average='binary'))\n",
    "        results['F1 Score'].append(f1_score(y_test, predictions, pos_label='2', average='binary'))\n",
    "        \n",
    "        fold_idx += 1\n",
    "    \n",
    "    # Convert results to DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df['Classifier'] = model_name\n",
    "    results_file = f\"Results/wilt_second_benchmark.csv\"\n",
    "    results_df.to_csv(results_file, index=False)\n",
    "    print(f'Results saved to {results_file}')\n",
    "    return results_df\n",
    "\n",
    "# Main function to run the evaluation\n",
    "def run_evaluation(file_path, target_column, model, model_name, n_splits=5):\n",
    "    df = load_arff_to_dataframe(file_path)\n",
    "    X, y = preprocess_data(df, target_column)\n",
    "    results_df = evaluate_model(X, y, model, model_name, n_splits)\n",
    "    return results_df\n",
    "\n",
    "# Run evaluation for the wilt dataset\n",
    "results_df = run_evaluation(file_path, target_column, model, model_name)\n",
    "\n",
    "# Display the results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeb2731-f000-402c-8d9b-d46a5592bc43",
   "metadata": {},
   "source": [
    "<a id=\"6.1.2-sick\"></a>\n",
    "#### 6.1.2. sick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a1cd8c4-3604-42d4-9b99-f50a701a79b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Results/sick_second_benchmark.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.965563</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.966887</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.962865</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.969496</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.708861</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold  Accuracy  Precision    Recall  F1 Score  Classifier\n",
       "0     1  0.965563   0.794118  0.586957  0.675000  KNNVariant\n",
       "1     2  0.966887   0.892857  0.531915  0.666667  KNNVariant\n",
       "2     3  0.962865   0.750000  0.586957  0.658537  KNNVariant\n",
       "3     4  0.965517   0.857143  0.521739  0.648649  KNNVariant\n",
       "4     5  0.969496   0.848485  0.608696  0.708861  KNNVariant"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from knn2 import KNNVariant\n",
    "\n",
    "# Define parameters for the dataset\n",
    "file_path = 'DS/sick.arff'\n",
    "df = load_arff_to_dataframe(file_path)\n",
    "target_column = 'Class'\n",
    "model = KNNVariant(k=5, max_k=9, min_k=3, weight_distance=True)\n",
    "model_name = 'KNNVariant'\n",
    "\n",
    "\n",
    "def preprocess_data(df, target_column):\n",
    "    # Drop the column 'TBG' as it only contains missing values\n",
    "    df = df.drop(columns=['TBG'])\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column].values\n",
    "    \n",
    "    # Identify numeric and categorical columns\n",
    "    numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_features = X.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    # Create preprocessing pipelines for both numeric and categorical data\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values with mean\n",
    "        ('scaler', StandardScaler())  # Standardize numeric features\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values with most frequent value\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-hot encode categorical features\n",
    "    ])\n",
    "\n",
    "    # Combine preprocessing steps\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Fit and transform the features\n",
    "    X_preprocessed = preprocessor.fit_transform(X)\n",
    "    \n",
    "    return X_preprocessed, y\n",
    "\n",
    "\n",
    "# Model evaluation\n",
    "def evaluate_model(X, y, model, model_name, n_splits, random_seed=42):\n",
    "    # Stratified 5-Fold cross-validation\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "    results = {\n",
    "        'Fold': [],\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1 Score': []\n",
    "    }\n",
    "    \n",
    "    fold_idx = 1\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Fit the model and make predictions\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Record metrics\n",
    "        results['Fold'].append(fold_idx)\n",
    "        results['Accuracy'].append(accuracy_score(y_test, predictions))\n",
    "        results['Precision'].append(precision_score(y_test, predictions, pos_label='sick', average='binary'))\n",
    "        results['Recall'].append(recall_score(y_test, predictions, pos_label='sick', average='binary'))\n",
    "        results['F1 Score'].append(f1_score(y_test, predictions, pos_label='sick', average='binary'))\n",
    "        \n",
    "        fold_idx += 1\n",
    "    \n",
    "    # Convert results to DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df['Classifier'] = model_name\n",
    "    results_file = f\"Results/sick_second_benchmark.csv\"\n",
    "    results_df.to_csv(results_file, index=False)\n",
    "    print(f'Results saved to {results_file}')\n",
    "    return results_df\n",
    "\n",
    "# Main function to run the evaluation\n",
    "def run_evaluation(file_path, target_column, model, model_name, n_splits=5):\n",
    "    df = load_arff_to_dataframe(file_path)\n",
    "    X, y = preprocess_data(df, target_column)\n",
    "    results_df = evaluate_model(X, y, model, model_name, n_splits)\n",
    "    return results_df\n",
    "\n",
    "# Run evaluation for the wilt dataset\n",
    "results_df = run_evaluation(file_path, target_column, model, model_name)\n",
    "\n",
    "# Display the results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d85d39-c8fd-448a-a3d2-0cfde76c9f45",
   "metadata": {},
   "source": [
    "<a id=\"6.1.3-ozone\"></a>\n",
    "#### 6.1.3. ozone-level-8hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb8b5a39-f00a-4077-b5ff-b05c1d020d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Results/ozone-level-8hr_second_benchmark.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.934911</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.18750</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.942801</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.37500</td>\n",
       "      <td>0.452830</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.930966</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.28125</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.952663</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.37500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold  Accuracy  Precision   Recall  F1 Score  Classifier\n",
       "0     1  0.934911   0.461538  0.18750  0.266667  KNNVariant\n",
       "1     2  0.942801   0.571429  0.37500  0.452830  KNNVariant\n",
       "2     3  0.930966   0.428571  0.28125  0.339623  KNNVariant\n",
       "3     4  0.952663   0.750000  0.37500  0.500000  KNNVariant\n",
       "4     5  0.934783   0.466667  0.21875  0.297872  KNNVariant"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from knn2 import KNNVariant\n",
    "\n",
    "# Define parameters for the dataset\n",
    "file_path = 'DS/ozone-level-8hr.arff'\n",
    "df = load_arff_to_dataframe(file_path)\n",
    "target_column = 'Class'\n",
    "model = KNNVariant(k=5, max_k=9, min_k=3, weight_distance=True)\n",
    "model_name = 'KNNVariant'\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(df, target_column):\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "    return X, y\n",
    "\n",
    "# Model evaluation\n",
    "def evaluate_model(X, y, model, model_name, n_splits, random_seed=42):\n",
    "    # Stratified 5-Fold cross-validation\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "    results = {\n",
    "        'Fold': [],\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1 Score': []\n",
    "    }\n",
    "    \n",
    "    fold_idx = 1\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Fit the model and make predictions\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Record metrics\n",
    "        results['Fold'].append(fold_idx)\n",
    "        results['Accuracy'].append(accuracy_score(y_test, predictions))\n",
    "        results['Precision'].append(precision_score(y_test, predictions, pos_label='2', average='binary'))\n",
    "        results['Recall'].append(recall_score(y_test, predictions, pos_label='2', average='binary'))\n",
    "        results['F1 Score'].append(f1_score(y_test, predictions, pos_label='2', average='binary'))\n",
    "        \n",
    "        fold_idx += 1\n",
    "    \n",
    "    # Convert results to DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df['Classifier'] = model_name\n",
    "    results_file = \"Results/ozone-level-8hr_second_benchmark.csv\"\n",
    "    results_df.to_csv(results_file, index=False)\n",
    "    print(f'Results saved to {results_file}')\n",
    "    return results_df\n",
    "\n",
    "# Main function to run the evaluation\n",
    "def run_evaluation(file_path, target_column, model, model_name, n_splits=5):\n",
    "    df = load_arff_to_dataframe(file_path)\n",
    "    X, y = preprocess_data(df, target_column)\n",
    "    results_df = evaluate_model(X, y, model, model_name, n_splits)\n",
    "    return results_df\n",
    "\n",
    "# Run evaluation for the wilt dataset\n",
    "results_df = run_evaluation(file_path, target_column, model, model_name)\n",
    "\n",
    "# Display the results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ef849a-4a8c-4203-b4f4-23165cae4955",
   "metadata": {},
   "source": [
    "<a id=\"6.1.4-pc1\"></a>\n",
    "#### 6.1.4. pc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29fc57a9-8850-4e24-87f6-b788048d7c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Results/pc1_second_benchmark.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.941441</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.909910</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.923423</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.918552</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold  Accuracy  Precision    Recall  F1 Score  Classifier\n",
       "0     1  0.941441   0.600000  0.400000  0.480000  KNNVariant\n",
       "1     2  0.918919   0.333333  0.200000  0.250000  KNNVariant\n",
       "2     3  0.909910   0.375000  0.375000  0.375000  KNNVariant\n",
       "3     4  0.923423   0.444444  0.250000  0.320000  KNNVariant\n",
       "4     5  0.918552   0.384615  0.333333  0.357143  KNNVariant"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from knn2 import KNNVariant\n",
    "\n",
    "# Define parameters for the dataset\n",
    "file_path = 'DS/pc1.arff'\n",
    "df = load_arff_to_dataframe(file_path)\n",
    "target_column = 'defects'\n",
    "model = KNNVariant(k=5, max_k=9, min_k=3, weight_distance=True)\n",
    "model_name = 'KNNVariant'\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(df, target_column):\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "    return X, y\n",
    "\n",
    "# Model evaluation\n",
    "def evaluate_model(X, y, model, model_name, n_splits, random_seed=42):\n",
    "    # Stratified 5-Fold cross-validation\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "    results = {\n",
    "        'Fold': [],\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1 Score': []\n",
    "    }\n",
    "    \n",
    "    fold_idx = 1\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Fit the model and make predictions\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Record metrics\n",
    "        results['Fold'].append(fold_idx)\n",
    "        results['Accuracy'].append(accuracy_score(y_test, predictions))\n",
    "        results['Precision'].append(precision_score(y_test, predictions, pos_label='true', average='binary'))\n",
    "        results['Recall'].append(recall_score(y_test, predictions, pos_label='true', average='binary'))\n",
    "        results['F1 Score'].append(f1_score(y_test, predictions, pos_label='true', average='binary'))\n",
    "        \n",
    "        fold_idx += 1\n",
    "    \n",
    "    # Convert results to DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df['Classifier'] = model_name\n",
    "    results_file = \"Results/pc1_second_benchmark.csv\"\n",
    "    results_df.to_csv(results_file, index=False)\n",
    "    print(f'Results saved to {results_file}')\n",
    "    return results_df\n",
    "\n",
    "# Main function to run the evaluation\n",
    "def run_evaluation(file_path, target_column, model, model_name, n_splits=5):\n",
    "    df = load_arff_to_dataframe(file_path)\n",
    "    X, y = preprocess_data(df, target_column)\n",
    "    results_df = evaluate_model(X, y, model, model_name, n_splits)\n",
    "    return results_df\n",
    "\n",
    "# Run evaluation for the wilt dataset\n",
    "results_df = run_evaluation(file_path, target_column, model, model_name)\n",
    "\n",
    "# Display the results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ce406b-f419-4d36-8a9e-08856bf9d072",
   "metadata": {},
   "source": [
    "<a id=\"6.1.5-climate\"></a>\n",
    "#### 6.1.5. climate-model-simulation-crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2479808a-6bf9-4023-847c-d1ba570375b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Results/climate-model-simulation-crashes_second_benchmark.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold  Accuracy  Precision    Recall  F1 Score  Classifier\n",
       "0     1  0.916667   0.666667  0.200000  0.307692  KNNVariant\n",
       "1     2  0.898148   0.250000  0.111111  0.153846  KNNVariant\n",
       "2     3  0.916667   0.500000  0.222222  0.307692  KNNVariant\n",
       "3     4  0.916667   0.000000  0.000000  0.000000  KNNVariant\n",
       "4     5  0.907407   0.400000  0.222222  0.285714  KNNVariant"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from knn2 import KNNVariant\n",
    "\n",
    "# Define parameters for the dataset\n",
    "file_path = 'DS/climate-model-simulation-crashes.arff'\n",
    "df = load_arff_to_dataframe(file_path)\n",
    "target_column = 'outcome'\n",
    "model = KNNVariant(k=5, max_k=9, min_k=3, weight_distance=True)\n",
    "model_name = 'KNNVariant'\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(df, target_column):\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "    return X, y\n",
    "\n",
    "# Model evaluation\n",
    "def evaluate_model(X, y, model, model_name, n_splits, random_seed=42):\n",
    "    # Stratified 5-Fold cross-validation\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "    results = {\n",
    "        'Fold': [],\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1 Score': []\n",
    "    }\n",
    "    \n",
    "    fold_idx = 1\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Fit the model and make predictions\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Record metrics\n",
    "        results['Fold'].append(fold_idx)\n",
    "        results['Accuracy'].append(accuracy_score(y_test, predictions))\n",
    "        results['Precision'].append(precision_score(y_test, predictions, pos_label='0', average='binary', zero_division=0))  \n",
    "        results['Recall'].append(recall_score(y_test, predictions, pos_label='0', average='binary', zero_division=0))  \n",
    "        results['F1 Score'].append(f1_score(y_test, predictions, pos_label='0', average='binary', zero_division=0))  \n",
    "        \n",
    "        fold_idx += 1\n",
    "    \n",
    "    # Convert results to DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df['Classifier'] = model_name\n",
    "    results_file = \"Results/climate-model-simulation-crashes_second_benchmark.csv\"\n",
    "    results_df.to_csv(results_file, index=False)\n",
    "    print(f'Results saved to {results_file}')\n",
    "    return results_df\n",
    "\n",
    "# Main function to run the evaluation\n",
    "def run_evaluation(file_path, target_column, model, model_name, n_splits=5):\n",
    "    df = load_arff_to_dataframe(file_path)\n",
    "    X, y = preprocess_data(df, target_column)\n",
    "    results_df = evaluate_model(X, y, model, model_name, n_splits)\n",
    "    return results_df\n",
    "\n",
    "# Run evaluation for the wilt dataset\n",
    "results_df = run_evaluation(file_path, target_column, model, model_name)\n",
    "\n",
    "# Display the results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3baaa5-2747-4a1e-9aa8-3fc4c8bb73aa",
   "metadata": {},
   "source": [
    "<a id=\"6.1.6-pc3\"></a>\n",
    "#### 6.1.6 pc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d70ecf6-3fbc-4eb3-b7d9-6c49af5f2faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Results/pc3_second_benchmark.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.891374</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.18750</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.881789</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.872204</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.891026</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.18750</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold  Accuracy  Precision   Recall  F1 Score  Classifier\n",
       "0     1  0.891374   0.428571  0.18750  0.260870  KNNVariant\n",
       "1     2  0.881789   0.368421  0.21875  0.274510  KNNVariant\n",
       "2     3  0.872204   0.333333  0.25000  0.285714  KNNVariant\n",
       "3     4  0.891026   0.437500  0.21875  0.291667  KNNVariant\n",
       "4     5  0.875000   0.315789  0.18750  0.235294  KNNVariant"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from knn2 import KNNVariant\n",
    "\n",
    "# Define parameters for the dataset\n",
    "file_path = 'DS/pc3.arff'\n",
    "df = load_arff_to_dataframe(file_path)\n",
    "target_column = 'c'\n",
    "model = KNNVariant(k=5, max_k=9, min_k=3, weight_distance=True)\n",
    "model_name = 'KNNVariant'\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(df, target_column):\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "    return X, y\n",
    "\n",
    "# Model evaluation\n",
    "def evaluate_model(X, y, model, model_name, n_splits, random_seed=42):\n",
    "    # Stratified 5-Fold cross-validation\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "    results = {\n",
    "        'Fold': [],\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1 Score': []\n",
    "    }\n",
    "    \n",
    "    fold_idx = 1\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Fit the model and make predictions\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Record metrics\n",
    "        results['Fold'].append(fold_idx)\n",
    "        results['Accuracy'].append(accuracy_score(y_test, predictions))\n",
    "        results['Precision'].append(precision_score(y_test, predictions, pos_label='TRUE', average='binary'))\n",
    "        results['Recall'].append(recall_score(y_test, predictions, pos_label='TRUE', average='binary'))\n",
    "        results['F1 Score'].append(f1_score(y_test, predictions, pos_label='TRUE', average='binary'))\n",
    "        \n",
    "        fold_idx += 1\n",
    "    \n",
    "    # Convert results to DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df['Classifier'] = model_name\n",
    "    results_file = \"Results/pc3_second_benchmark.csv\"\n",
    "    results_df.to_csv(results_file, index=False)\n",
    "    print(f'Results saved to {results_file}')\n",
    "    return results_df\n",
    "\n",
    "# Main function to run the evaluation\n",
    "def run_evaluation(file_path, target_column, model, model_name, n_splits=5):\n",
    "    df = load_arff_to_dataframe(file_path)\n",
    "    X, y = preprocess_data(df, target_column)\n",
    "    results_df = evaluate_model(X, y, model, model_name, n_splits)\n",
    "    return results_df\n",
    "\n",
    "# Run evaluation for the wilt dataset\n",
    "results_df = run_evaluation(file_path, target_column, model, model_name)\n",
    "\n",
    "# Display the results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14865648-a8d7-400d-bb21-e3abbdecf7ec",
   "metadata": {},
   "source": [
    "<a id=\"6.1.7-pc4\"></a>\n",
    "#### 6.1.7. pc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31972378-8086-4a2e-b14f-512b1d9f8389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Results/pc4_second_benchmark.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.869863</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.883562</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.863014</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.900344</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.508475</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.903780</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold  Accuracy  Precision    Recall  F1 Score  Classifier\n",
       "0     1  0.869863   0.464286  0.361111  0.406250  KNNVariant\n",
       "1     2  0.883562   0.535714  0.416667  0.468750  KNNVariant\n",
       "2     3  0.863014   0.433333  0.361111  0.393939  KNNVariant\n",
       "3     4  0.900344   0.625000  0.428571  0.508475  KNNVariant\n",
       "4     5  0.903780   0.620690  0.514286  0.562500  KNNVariant"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from knn2 import KNNVariant\n",
    "\n",
    "# Define parameters for the dataset\n",
    "file_path = 'DS/pc4.arff'\n",
    "df = load_arff_to_dataframe(file_path)\n",
    "target_column = 'c'\n",
    "model = KNNVariant(k=5, max_k=9, min_k=3, weight_distance=True)\n",
    "model_name = 'KNNVariant'\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(df, target_column):\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "    return X, y\n",
    "\n",
    "# Model evaluation\n",
    "def evaluate_model(X, y, model, model_name, n_splits, random_seed=42):\n",
    "    # Stratified 5-Fold cross-validation\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "    results = {\n",
    "        'Fold': [],\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1 Score': []\n",
    "    }\n",
    "    \n",
    "    fold_idx = 1\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Fit the model and make predictions\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Record metrics\n",
    "        results['Fold'].append(fold_idx)\n",
    "        results['Accuracy'].append(accuracy_score(y_test, predictions))\n",
    "        results['Precision'].append(precision_score(y_test, predictions, pos_label='TRUE', average='binary'))\n",
    "        results['Recall'].append(recall_score(y_test, predictions, pos_label='TRUE', average='binary'))\n",
    "        results['F1 Score'].append(f1_score(y_test, predictions, pos_label='TRUE', average='binary'))\n",
    "        \n",
    "        fold_idx += 1\n",
    "    \n",
    "    # Convert results to DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df['Classifier'] = model_name\n",
    "    results_file = \"Results/pc4_second_benchmark.csv\"\n",
    "    results_df.to_csv(results_file, index=False)\n",
    "    print(f'Results saved to {results_file}')\n",
    "    return results_df\n",
    "\n",
    "# Main function to run the evaluation\n",
    "def run_evaluation(file_path, target_column, model, model_name, n_splits=5):\n",
    "    df = load_arff_to_dataframe(file_path)\n",
    "    X, y = preprocess_data(df, target_column)\n",
    "    results_df = evaluate_model(X, y, model, model_name, n_splits)\n",
    "    return results_df\n",
    "\n",
    "# Run evaluation for the wilt dataset\n",
    "results_df = run_evaluation(file_path, target_column, model, model_name)\n",
    "\n",
    "# Display the results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba246bd5-97bb-4dce-bc39-e90d8fffbcc9",
   "metadata": {},
   "source": [
    "<a id=\"6.1.8-internet\"></a>\n",
    "#### 6.1.8. Internet-Advertisements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c34097f-5eda-4e2a-ad8c-6258cfcdffd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Results/Internet-Advertisements_second_benchmark.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.949695</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.795031</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.967988</td>\n",
       "      <td>0.908046</td>\n",
       "      <td>0.858696</td>\n",
       "      <td>0.882682</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.946646</td>\n",
       "      <td>0.901408</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.785276</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.948171</td>\n",
       "      <td>0.881579</td>\n",
       "      <td>0.728261</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.958779</td>\n",
       "      <td>0.932432</td>\n",
       "      <td>0.758242</td>\n",
       "      <td>0.836364</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold  Accuracy  Precision    Recall  F1 Score  Classifier\n",
       "0     1  0.949695   0.927536  0.695652  0.795031  KNNVariant\n",
       "1     2  0.967988   0.908046  0.858696  0.882682  KNNVariant\n",
       "2     3  0.946646   0.901408  0.695652  0.785276  KNNVariant\n",
       "3     4  0.948171   0.881579  0.728261  0.797619  KNNVariant\n",
       "4     5  0.958779   0.932432  0.758242  0.836364  KNNVariant"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from knn2 import KNNVariant\n",
    "\n",
    "# Define parameters for the dataset\n",
    "file_path = 'DS/Internet-Advertisements.arff'\n",
    "df = load_arff_to_dataframe(file_path)\n",
    "target_column = 'class'\n",
    "model = KNNVariant(k=5, max_k=9, min_k=3, weight_distance=True)\n",
    "model_name = 'KNNVariant'\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(df, target_column):\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "    return X, y\n",
    "\n",
    "# Model evaluation\n",
    "def evaluate_model(X, y, model, model_name, n_splits, random_seed=42):\n",
    "    # Stratified 5-Fold cross-validation\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "    results = {\n",
    "        'Fold': [],\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1 Score': []\n",
    "    }\n",
    "    \n",
    "    fold_idx = 1\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Fit the model and make predictions\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Record metrics\n",
    "        results['Fold'].append(fold_idx)\n",
    "        results['Accuracy'].append(accuracy_score(y_test, predictions))\n",
    "        results['Precision'].append(precision_score(y_test, predictions, pos_label='ad', average='binary'))\n",
    "        results['Recall'].append(recall_score(y_test, predictions, pos_label='ad', average='binary'))\n",
    "        results['F1 Score'].append(f1_score(y_test, predictions, pos_label='ad', average='binary'))\n",
    "        \n",
    "        fold_idx += 1\n",
    "    \n",
    "    # Convert results to DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df['Classifier'] = model_name\n",
    "    results_file = \"Results/Internet-Advertisements_second_benchmark.csv\"\n",
    "    results_df.to_csv(results_file, index=False)\n",
    "    print(f'Results saved to {results_file}')\n",
    "    return results_df\n",
    "\n",
    "# Main function to run the evaluation\n",
    "def run_evaluation(file_path, target_column, model, model_name, n_splits=5):\n",
    "    df = load_arff_to_dataframe(file_path)\n",
    "    X, y = preprocess_data(df, target_column)\n",
    "    results_df = evaluate_model(X, y, model, model_name, n_splits)\n",
    "    return results_df\n",
    "\n",
    "# Run evaluation for the wilt dataset\n",
    "results_df = run_evaluation(file_path, target_column, model, model_name)\n",
    "\n",
    "# Display the results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2500deed-72bd-4efc-9de6-94b9c6ceb24b",
   "metadata": {},
   "source": [
    "<a id=\"6.1.9-churn\"></a>\n",
    "#### 6.1.9. churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3986bd0-9cd0-428b-99d6-8a3ea56548ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Results/churn_second_benchmark.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.219858</td>\n",
       "      <td>0.329787</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.644068</td>\n",
       "      <td>0.269504</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.262411</td>\n",
       "      <td>0.393617</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.176056</td>\n",
       "      <td>0.271739</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.260563</td>\n",
       "      <td>0.387435</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold  Accuracy  Precision    Recall  F1 Score  Classifier\n",
       "0     1     0.874   0.659574  0.219858  0.329787  KNNVariant\n",
       "1     2     0.876   0.644068  0.269504  0.380000  KNNVariant\n",
       "2     3     0.886   0.787234  0.262411  0.393617  KNNVariant\n",
       "3     4     0.866   0.595238  0.176056  0.271739  KNNVariant\n",
       "4     5     0.883   0.755102  0.260563  0.387435  KNNVariant"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from knn2 import KNNVariant\n",
    "\n",
    "# Define parameters for the dataset\n",
    "file_path = 'DS/churn.arff'\n",
    "df = load_arff_to_dataframe(file_path)\n",
    "target_column = 'class'\n",
    "model = KNNVariant(k=5, max_k=9, min_k=3, weight_distance=True)\n",
    "model_name = 'KNNVariant'\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(df, target_column):\n",
    "    # Separate features and target\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column].values\n",
    "    \n",
    "    # Identify numeric and categorical columns\n",
    "    numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_features = X.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    # Create preprocessing pipelines for both numeric and categorical data\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler())  # Standardize numeric features\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-hot encode categorical features\n",
    "    ])\n",
    "\n",
    "    # Combine preprocessing steps\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Fit and transform the features\n",
    "    X_preprocessed = preprocessor.fit_transform(X)\n",
    "    \n",
    "    return X_preprocessed, y\n",
    "\n",
    "# Model evaluation\n",
    "def evaluate_model(X, y, model, model_name, n_splits, random_seed=42):\n",
    "    # Stratified 5-Fold cross-validation\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "    results = {\n",
    "        'Fold': [],\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1 Score': []\n",
    "    }\n",
    "    \n",
    "    fold_idx = 1\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Fit the model and make predictions\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Record metrics\n",
    "        results['Fold'].append(fold_idx)\n",
    "        results['Accuracy'].append(accuracy_score(y_test, predictions))\n",
    "        results['Precision'].append(precision_score(y_test, predictions, pos_label='1', average='binary'))\n",
    "        results['Recall'].append(recall_score(y_test, predictions, pos_label='1', average='binary'))\n",
    "        results['F1 Score'].append(f1_score(y_test, predictions, pos_label='1', average='binary'))\n",
    "        \n",
    "        fold_idx += 1\n",
    "    \n",
    "    # Convert results to DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df['Classifier'] = model_name\n",
    "    results_file = \"Results/churn_second_benchmark.csv\"\n",
    "    results_df.to_csv(results_file, index=False)\n",
    "    print(f'Results saved to {results_file}')\n",
    "    return results_df\n",
    "\n",
    "# Main function to run the evaluation\n",
    "def run_evaluation(file_path, target_column, model, model_name, n_splits=5):\n",
    "    df = load_arff_to_dataframe(file_path)\n",
    "    X, y = preprocess_data(df, target_column)\n",
    "    results_df = evaluate_model(X, y, model, model_name, n_splits)\n",
    "    return results_df\n",
    "\n",
    "# Run evaluation for the wilt dataset\n",
    "results_df = run_evaluation(file_path, target_column, model, model_name)\n",
    "\n",
    "# Display the results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eace5e2-71ab-43a3-b231-7fb9aab7fc3e",
   "metadata": {},
   "source": [
    "<a id=\"6.1.10-kc1\"></a>\n",
    "#### 6.1.10. kc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e7a9457-6a81-40ed-a1e1-1152d8830017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Results/kc1_second_benchmark.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.791469</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>0.276923</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.800948</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.184615</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.781991</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.323077</td>\n",
       "      <td>0.313433</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.741706</td>\n",
       "      <td>0.282828</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.339394</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.809976</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.323077</td>\n",
       "      <td>0.344262</td>\n",
       "      <td>KNNVariant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold  Accuracy  Precision    Recall  F1 Score  Classifier\n",
       "0     1  0.791469   0.305085  0.276923  0.290323  KNNVariant\n",
       "1     2  0.800948   0.279070  0.184615  0.222222  KNNVariant\n",
       "2     3  0.781991   0.304348  0.323077  0.313433  KNNVariant\n",
       "3     4  0.741706   0.282828  0.424242  0.339394  KNNVariant\n",
       "4     5  0.809976   0.368421  0.323077  0.344262  KNNVariant"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from knn2 import KNNVariant\n",
    "\n",
    "# Define parameters for the dataset\n",
    "file_path = 'DS/kc1.arff'\n",
    "df = load_arff_to_dataframe(file_path)\n",
    "target_column = 'defects'\n",
    "model = KNNVariant(k=5, max_k=9, min_k=3, weight_distance=True)\n",
    "model_name = 'KNNVariant'\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(df, target_column):\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "    return X, y\n",
    "\n",
    "# Model evaluation\n",
    "def evaluate_model(X, y, model, model_name, n_splits, random_seed=42):\n",
    "    # Stratified 5-Fold cross-validation\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "    results = {\n",
    "        'Fold': [],\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1 Score': []\n",
    "    }\n",
    "    \n",
    "    fold_idx = 1\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Fit the model and make predictions\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Record metrics\n",
    "        results['Fold'].append(fold_idx)\n",
    "        results['Accuracy'].append(accuracy_score(y_test, predictions))\n",
    "        results['Precision'].append(precision_score(y_test, predictions, pos_label='true', average='binary'))\n",
    "        results['Recall'].append(recall_score(y_test, predictions, pos_label='true', average='binary'))\n",
    "        results['F1 Score'].append(f1_score(y_test, predictions, pos_label='true', average='binary'))\n",
    "        \n",
    "        fold_idx += 1\n",
    "    \n",
    "    # Convert results to DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df['Classifier'] = model_name\n",
    "    results_file = \"Results/kc1_second_benchmark.csv\"\n",
    "    results_df.to_csv(results_file, index=False)\n",
    "    print(f'Results saved to {results_file}')\n",
    "    return results_df\n",
    "\n",
    "# Main function to run the evaluation\n",
    "def run_evaluation(file_path, target_column, model, model_name, n_splits=5):\n",
    "    df = load_arff_to_dataframe(file_path)\n",
    "    X, y = preprocess_data(df, target_column)\n",
    "    results_df = evaluate_model(X, y, model, model_name, n_splits)\n",
    "    return results_df\n",
    "\n",
    "# Run evaluation for the wilt dataset\n",
    "results_df = run_evaluation(file_path, target_column, model, model_name)\n",
    "\n",
    "# Display the results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb4449f-7890-4fc3-bfe7-c72ae1b9e73e",
   "metadata": {},
   "source": [
    "<a id=\"6.2-Results\"></a>\n",
    "### 6.2. Results and Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450203df-5056-4107-a9d6-b501c9c5b8bb",
   "metadata": {},
   "source": [
    "After evluating the datasets with the KNNVariant, I applied the script that iterates over the CSV files and analyzes the results. As prviously explained, the script reads each .csv file in the Results folder, calculates the **mean** and **standard deviation** for **accuracy**, **precision**, **recall**, and **F1 score**. It compiles these statistics into a summary DataFrame, providing a comprehensive overview of the model's performance across all datasets. The summary is then saved to a new CSV file named **summary_second_analysis.csv** for easy reference and further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e4527f9-e87e-4169-82f1-780ca3bc7a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary analysis saved to Results/summary_second_analysis.csv\n",
      "                            Dataset  Mean Accuracy  Std Accuracy  \\\n",
      "0           Internet-Advertisements       0.954256      0.009010   \n",
      "1                             churn       0.877000      0.007874   \n",
      "2  climate-model-simulation-crashes       0.911111      0.008282   \n",
      "3                               kc1       0.785218      0.026473   \n",
      "4                   ozone-level-8hr       0.939225      0.008659   \n",
      "5                               pc1       0.922449      0.011689   \n",
      "6                               pc3       0.882279      0.008859   \n",
      "7                               pc4       0.884112      0.018019   \n",
      "8                              sick       0.966066      0.002411   \n",
      "9                              wilt       0.970863      0.005430   \n",
      "\n",
      "   Mean Precision  Std Precision  Mean Recall  Std Recall  Mean F1 Score  \\\n",
      "0        0.910200       0.020591     0.747301    0.067502       0.819394   \n",
      "1        0.688243       0.080145     0.237679    0.039570       0.352516   \n",
      "2        0.363333       0.253421     0.151111    0.096097       0.210989   \n",
      "3        0.307950       0.035858     0.306387    0.086809       0.301927   \n",
      "4        0.535641       0.131285     0.287500    0.086715       0.371398   \n",
      "5        0.427479       0.104291     0.311667    0.084492       0.356429   \n",
      "6        0.376723       0.054878     0.212500    0.026146       0.269611   \n",
      "7        0.535805       0.087716     0.416349    0.062936       0.467983   \n",
      "8        0.828520       0.056361     0.567253    0.038126       0.671543   \n",
      "9        0.883017       0.062790     0.529100    0.068898       0.660858   \n",
      "\n",
      "   Std F1 Score  \n",
      "0      0.040389  \n",
      "1      0.051734  \n",
      "2      0.134228  \n",
      "3      0.049538  \n",
      "4      0.100690  \n",
      "5      0.084068  \n",
      "6      0.022493  \n",
      "7      0.070475  \n",
      "8      0.023031  \n",
      "9      0.069075  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Function to analyze a single results CSV file\n",
    "def analyze_results(file_path, benchmark):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Calculate mean and standard deviation for each metric\n",
    "    summary = {\n",
    "        'Dataset': os.path.basename(file_path).replace(f'_{benchmark}_benchmark.csv', ''),\n",
    "        'Mean Accuracy': df['Accuracy'].mean(),\n",
    "        'Std Accuracy': df['Accuracy'].std(),\n",
    "        'Mean Precision': df['Precision'].mean(),\n",
    "        'Std Precision': df['Precision'].std(),\n",
    "        'Mean Recall': df['Recall'].mean(),\n",
    "        'Std Recall': df['Recall'].std(),\n",
    "        'Mean F1 Score': df['F1 Score'].mean(),\n",
    "        'Std F1 Score': df['F1 Score'].std()\n",
    "    }\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Main function to analyze all results\n",
    "def analyze_all_results(results_folder, benchmark):\n",
    "    results_files = glob.glob(os.path.join(results_folder, f'*_{benchmark}_benchmark.csv'))\n",
    "    analysis_results = []\n",
    "\n",
    "    for file_path in results_files:\n",
    "        summary = analyze_results(file_path, benchmark)\n",
    "        analysis_results.append(summary)\n",
    "\n",
    "    # Create a summary DataFrame\n",
    "    summary_df = pd.DataFrame(analysis_results)\n",
    "    summary_df = summary_df[['Dataset', 'Mean Accuracy', 'Std Accuracy', 'Mean Precision', 'Std Precision', 'Mean Recall', 'Std Recall', 'Mean F1 Score', 'Std F1 Score']]\n",
    "    \n",
    "    # Sort the summary DataFrame by Dataset name\n",
    "    summary_df = summary_df.sort_values(by='Dataset').reset_index(drop=True)\n",
    "    \n",
    "    # Save the summary DataFrame to a CSV file\n",
    "    summary_file = os.path.join(results_folder, f'summary_{benchmark}_analysis.csv')\n",
    "    summary_df.to_csv(summary_file, index=False)\n",
    "    print(f'Summary analysis saved to {summary_file}')\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "# Define the results folder and benchmark type\n",
    "results_folder = 'Results'\n",
    "benchmark = 'second'  # Specify the benchmark type as 'first'\n",
    "\n",
    "# Run the analysis\n",
    "summary_df = analyze_all_results(results_folder, benchmark)\n",
    "\n",
    "# Display the summary DataFrame\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6378ac86-c902-464d-86cd-f1176f26b891",
   "metadata": {},
   "source": [
    "The following script was then generated to **compare the performance metrics** of the two algorithms. **Statistical tests** were performed to determine if the observed differences between the two algorithms were **statistically significant**. The Shapiro-Wilk test was used to check for normality, and depending on the results, either the **paired t-test** (for normally distributed differences) or the **Wilcoxon signed-rank test** (for non-normally distributed differences) was applied. The results of the comparison was saved in a file name **comparison_results_with_normality.csv**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a40c6357-0ffc-47fb-9d87-8a07eca72e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing Accuracy:\n",
      "Shapiro-Wilk test for normality of differences in Accuracy: statistic = 0.668, p-value = 0.000\n",
      "Differences in Accuracy are not normally distributed. Using Wilcoxon signed-rank test.\n",
      "Wilcoxon signed-rank test for Accuracy: w-statistic = 7.000, p-value = 0.037\n",
      "\n",
      "Comparing Precision:\n",
      "Shapiro-Wilk test for normality of differences in Precision: statistic = 0.952, p-value = 0.695\n",
      "Differences in Precision are normally distributed. Using paired t-test.\n",
      "Paired t-test for Precision: t-statistic = 2.133, p-value = 0.062\n",
      "\n",
      "Comparing Recall:\n",
      "Shapiro-Wilk test for normality of differences in Recall: statistic = 0.952, p-value = 0.686\n",
      "Differences in Recall are normally distributed. Using paired t-test.\n",
      "Paired t-test for Recall: t-statistic = -4.492, p-value = 0.002\n",
      "\n",
      "Comparing F1 Score:\n",
      "Shapiro-Wilk test for normality of differences in F1 Score: statistic = 0.964, p-value = 0.829\n",
      "Differences in F1 Score are normally distributed. Using paired t-test.\n",
      "Paired t-test for F1 Score: t-statistic = -2.645, p-value = 0.027\n",
      "\n",
      "Comparison Results:\n",
      "          statistic   p-value      test mean_first std_first mean_second  \\\n",
      "Accuracy        7.0  0.037109  Wilcoxon   0.915629  0.045761    0.909258   \n",
      "Precision  2.132986  0.061721    t-test   0.628918  0.243436    0.585691   \n",
      "Recall    -4.492026  0.001506    t-test   0.318412  0.206565    0.376685   \n",
      "F1 Score  -2.645439  0.026675    t-test   0.407555  0.225312    0.448265   \n",
      "\n",
      "          std_second                     better  \n",
      "Accuracy    0.055687              KNNClassifier  \n",
      "Precision   0.226928  No significant difference  \n",
      "Recall      0.186417                 KNNVariant  \n",
      "F1 Score    0.201747                 KNNVariant  \n",
      "Comparison results saved to Results/comparison_results_with_normality.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_rel, shapiro, wilcoxon\n",
    "\n",
    "# Load the summary data for both benchmarks\n",
    "results_folder = 'Results'  # Define the results folder\n",
    "first_summary_file = os.path.join(results_folder, 'summary_first_analysis.csv')\n",
    "second_summary_file = os.path.join(results_folder, 'summary_second_analysis.csv')\n",
    "\n",
    "first_df = pd.read_csv(first_summary_file)\n",
    "second_df = pd.read_csv(second_summary_file)\n",
    "\n",
    "# Merge the summaries on the 'Dataset' column\n",
    "merged_df = pd.merge(first_df, second_df, on='Dataset', suffixes=('_first', '_second'))\n",
    "\n",
    "# Function to perform normality test and statistical comparison\n",
    "def compare_metrics(metric):\n",
    "    print(f'\\nComparing {metric}:')\n",
    "    \n",
    "    first_values = merged_df[f'Mean {metric}_first']\n",
    "    second_values = merged_df[f'Mean {metric}_second']\n",
    "    differences = first_values - second_values\n",
    "    \n",
    "    # Shapiro-Wilk test for normality\n",
    "    stat, p_value_shapiro = shapiro(differences)\n",
    "    print(f'Shapiro-Wilk test for normality of differences in {metric}: statistic = {stat:.3f}, p-value = {p_value_shapiro:.3f}')\n",
    "    \n",
    "    if p_value_shapiro > 0.05:\n",
    "        print(f'Differences in {metric} are normally distributed. Using paired t-test.')\n",
    "        # Paired t-test\n",
    "        t_stat, p_value_ttest = ttest_rel(first_values, second_values)\n",
    "        print(f'Paired t-test for {metric}: t-statistic = {t_stat:.3f}, p-value = {p_value_ttest:.3f}')\n",
    "        test_result = (t_stat, p_value_ttest, 't-test')\n",
    "    else:\n",
    "        print(f'Differences in {metric} are not normally distributed. Using Wilcoxon signed-rank test.')\n",
    "        # Wilcoxon signed-rank test\n",
    "        w_stat, p_value_wilcoxon = wilcoxon(first_values, second_values)\n",
    "        print(f'Wilcoxon signed-rank test for {metric}: w-statistic = {w_stat:.3f}, p-value = {p_value_wilcoxon:.3f}')\n",
    "        test_result = (w_stat, p_value_wilcoxon, 'Wilcoxon')\n",
    "    \n",
    "    # Calculate means and standard deviations\n",
    "    mean_first = first_values.mean()\n",
    "    std_first = first_values.std()\n",
    "    mean_second = second_values.mean()\n",
    "    std_second = second_values.std()\n",
    "    \n",
    "    # Determine which algorithm is better based on the means\n",
    "    if test_result[1] < 0.05:  # If the difference is statistically significant\n",
    "        if mean_second > mean_first:\n",
    "            better = 'KNNVariant'\n",
    "        else:\n",
    "            better = 'KNNClassifier'\n",
    "    else:\n",
    "        better = 'No significant difference'\n",
    "    \n",
    "    return test_result + (mean_first, std_first, mean_second, std_second, better)\n",
    "\n",
    "# Metrics to compare\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "\n",
    "# Compare metrics\n",
    "results = {}\n",
    "for metric in metrics:\n",
    "    stat, p_value, test_used, mean_first, std_first, mean_second, std_second, better = compare_metrics(metric)\n",
    "    results[metric] = {\n",
    "        'statistic': stat,\n",
    "        'p-value': p_value,\n",
    "        'test': test_used,\n",
    "        'mean_first': mean_first,\n",
    "        'std_first': std_first,\n",
    "        'mean_second': mean_second,\n",
    "        'std_second': std_second,\n",
    "        'better': better\n",
    "    }\n",
    "\n",
    "# Display the results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print('\\nComparison Results:')\n",
    "print(results_df)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "comparison_results_file = os.path.join(results_folder, 'comparison_results_with_normality.csv')\n",
    "results_df.to_csv(comparison_results_file)\n",
    "print(f'Comparison results saved to {comparison_results_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8309cc8-0f31-437e-9946-5b2e039ca20b",
   "metadata": {},
   "source": [
    "**Accuracy**:\n",
    "- Shapiro-Wilk test: Differences are not normally distributed (statistic = 0.668, p-value = 0.000).\n",
    "- Wilcoxon signed-rank test: The difference in Accuracy is statistically significant (w-statistic = 7.000, p-value = 0.037).\n",
    "- Mean Accuracy: KNNClassifier = 0.9156, KNNVariant = 0.9093\n",
    "- Conclusion: KNNClassifier has a statistically significant better Accuracy.\n",
    "\n",
    "**Precision**:\n",
    "- Shapiro-Wilk test: Differences are normally distributed (statistic = 0.952, p-value = 0.695).\n",
    "- Paired t-test: The difference in Precision is not statistically significant (t-statistic = 2.133, p-value = 0.062).\n",
    "- Mean Precision: KNNClassifier = 0.6289, KNNVariant = 0.5857\n",
    "- Conclusion: There is no significant difference in Precision between the two algorithms.\n",
    "\n",
    "**Recall**:\n",
    "- Shapiro-Wilk test: Differences are normally distributed (statistic = 0.952, p-value = 0.686).\n",
    "- Paired t-test: The difference in Recall is statistically significant (t-statistic = -4.492, p-value = 0.002).\n",
    "- Mean Recall: KNNClassifier = 0.3184, KNNVariant = 0.3767\n",
    "- Conclusion: KNNVariant significantly improves Recall compared to KNNClassifier.\n",
    "\n",
    "**F1 Score**:\n",
    "- Shapiro-Wilk test: Differences are normally distributed (statistic = 0.964, p-value = 0.829).\n",
    "- Paired t-test: The difference in F1 Score is statistically significant (t-statistic = -2.645, p-value = 0.027).\n",
    "- Mean F1 Score: KNNClassifier = 0.4076, KNNVariant = 0.4483\n",
    "- Conclusion: KNNVariant significantly improves F1 Score compared to KNNClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1223e269-2228-40f3-a691-257ab1e085b7",
   "metadata": {},
   "source": [
    "The **KNNVariant** proposed to improve binary classification performance on imbalanced datasets has demonstrated **significant improvements** in **Recall** and **F1 Score** compared to the original KNNClassifier. These improvements suggest that KNNVariant is more **effective** at handling imbalanced data, making it a better choice for applications where identifying the minority class accurately is critical.\n",
    "\n",
    "While **Accuracy favors KNNClassifier**, and there is **no significant difference** in **Precision**, the enhanced Recall and F1 Score indicate that KNNVariant may achieve better performance in the context of imbalanced datasets. Therefore, KNNVariant is recommended for use in imbalanced scenarios and scenarios where achieving a higher F1 Score is a priority."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124e358a-b285-42e2-952c-b3eba92d784b",
   "metadata": {},
   "source": [
    "To further investigate the **impact of distance weighting** on the performance of the proposed KNNVariant, an additional evaluation was conducted with the distance_weight parameter set to **False**. This process was repeated for all 10 datasets used in the initial benchmarks. The results were then summarized: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12a9637d-3ba3-402e-9a2c-b20a9518e398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary analysis saved to Results/summary_additional_analysis.csv\n",
      "                            Dataset  Mean Accuracy  Std Accuracy  \\\n",
      "0           Internet-Advertisements       0.958830      0.009933   \n",
      "1                             churn       0.877000      0.007874   \n",
      "2  climate-model-simulation-crashes       0.911111      0.008282   \n",
      "3                               kc1       0.793276      0.019460   \n",
      "4                   ozone-level-8hr       0.939225      0.008659   \n",
      "5                               pc1       0.918841      0.015305   \n",
      "6                               pc3       0.889305      0.012826   \n",
      "7                               pc4       0.883416      0.012203   \n",
      "8                              sick       0.966861      0.001615   \n",
      "9                              wilt       0.970656      0.004979   \n",
      "\n",
      "   Mean Precision  Std Precision  Mean Recall  Std Recall  Mean F1 Score  \\\n",
      "0        0.933956       0.013922     0.760416    0.082204       0.836055   \n",
      "1        0.688243       0.080145     0.237679    0.039570       0.352516   \n",
      "2        0.363333       0.253421     0.151111    0.096097       0.210989   \n",
      "3        0.318652       0.029275     0.294126    0.081608       0.301285   \n",
      "4        0.535641       0.131285     0.287500    0.086715       0.371398   \n",
      "5        0.391111       0.128476     0.246667    0.054518       0.299613   \n",
      "6        0.432031       0.108520     0.225000    0.055902       0.293498   \n",
      "7        0.530801       0.060851     0.393651    0.048214       0.451908   \n",
      "8        0.838329       0.043443     0.571600    0.032456       0.678439   \n",
      "9        0.892095       0.046765     0.517634    0.072140       0.653771   \n",
      "\n",
      "   Std F1 Score  \n",
      "0      0.046394  \n",
      "1      0.051734  \n",
      "2      0.134228  \n",
      "3      0.048548  \n",
      "4      0.100690  \n",
      "5      0.075133  \n",
      "6      0.066535  \n",
      "7      0.053177  \n",
      "8      0.017509  \n",
      "9      0.068801  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Function to analyze a single results CSV file\n",
    "def analyze_results(file_path, benchmark):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Calculate mean and standard deviation for each metric\n",
    "    summary = {\n",
    "        'Dataset': os.path.basename(file_path).replace(f'_{benchmark}_benchmark.csv', ''),\n",
    "        'Mean Accuracy': df['Accuracy'].mean(),\n",
    "        'Std Accuracy': df['Accuracy'].std(),\n",
    "        'Mean Precision': df['Precision'].mean(),\n",
    "        'Std Precision': df['Precision'].std(),\n",
    "        'Mean Recall': df['Recall'].mean(),\n",
    "        'Std Recall': df['Recall'].std(),\n",
    "        'Mean F1 Score': df['F1 Score'].mean(),\n",
    "        'Std F1 Score': df['F1 Score'].std()\n",
    "    }\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Main function to analyze all results\n",
    "def analyze_all_results(results_folder, benchmark):\n",
    "    results_files = glob.glob(os.path.join(results_folder, f'*_{benchmark}_benchmark.csv'))\n",
    "    analysis_results = []\n",
    "\n",
    "    for file_path in results_files:\n",
    "        summary = analyze_results(file_path, benchmark)\n",
    "        analysis_results.append(summary)\n",
    "\n",
    "    # Create a summary DataFrame\n",
    "    summary_df = pd.DataFrame(analysis_results)\n",
    "    summary_df = summary_df[['Dataset', 'Mean Accuracy', 'Std Accuracy', 'Mean Precision', 'Std Precision', 'Mean Recall', 'Std Recall', 'Mean F1 Score', 'Std F1 Score']]\n",
    "    \n",
    "    # Sort the summary DataFrame by Dataset name\n",
    "    summary_df = summary_df.sort_values(by='Dataset').reset_index(drop=True)\n",
    "    \n",
    "    # Save the summary DataFrame to a CSV file\n",
    "    summary_file = os.path.join(results_folder, f'summary_{benchmark}_analysis.csv')\n",
    "    summary_df.to_csv(summary_file, index=False)\n",
    "    print(f'Summary analysis saved to {summary_file}')\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "# Define the results folder and benchmark type\n",
    "results_folder = 'Results'\n",
    "benchmark = 'additional'  # Specify the benchmark type as additional\n",
    "\n",
    "# Run the analysis\n",
    "summary_df = analyze_all_results(results_folder, benchmark)\n",
    "\n",
    "# Display the summary DataFrame\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c0e56a-bc82-4f88-9a51-84096536e7e0",
   "metadata": {},
   "source": [
    "Then, these results (**summary_additional_analysis.csv**) were compared against the results obtained in the first benchmark evaluation (and saved to a file named **comparison_results_with_normality_2.csv**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4a6f8d1-b6b5-401b-9654-7e0da1e69de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing Accuracy:\n",
      "Shapiro-Wilk test for normality of differences in Accuracy: statistic = 0.772, p-value = 0.007\n",
      "Differences in Accuracy are not normally distributed. Using Wilcoxon signed-rank test.\n",
      "Wilcoxon signed-rank test for Accuracy: w-statistic = 12.000, p-value = 0.131\n",
      "\n",
      "Comparing Precision:\n",
      "Shapiro-Wilk test for normality of differences in Precision: statistic = 0.912, p-value = 0.293\n",
      "Differences in Precision are normally distributed. Using paired t-test.\n",
      "Paired t-test for Precision: t-statistic = 1.622, p-value = 0.139\n",
      "\n",
      "Comparing Recall:\n",
      "Shapiro-Wilk test for normality of differences in Recall: statistic = 0.912, p-value = 0.293\n",
      "Differences in Recall are normally distributed. Using paired t-test.\n",
      "Paired t-test for Recall: t-statistic = -4.641, p-value = 0.001\n",
      "\n",
      "Comparing F1 Score:\n",
      "Shapiro-Wilk test for normality of differences in F1 Score: statistic = 0.886, p-value = 0.155\n",
      "Differences in F1 Score are normally distributed. Using paired t-test.\n",
      "Paired t-test for F1 Score: t-statistic = -2.570, p-value = 0.030\n",
      "\n",
      "Comparison Results:\n",
      "          statistic   p-value      test mean_first std_first mean_second  \\\n",
      "Accuracy       12.0  0.130859  Wilcoxon   0.915629  0.045761    0.910852   \n",
      "Precision  1.622185  0.139213    t-test   0.628918  0.243436    0.592419   \n",
      "Recall    -4.640797  0.001218    t-test   0.318412  0.206565    0.368538   \n",
      "F1 Score  -2.569872  0.030194    t-test   0.407555  0.225312    0.444947   \n",
      "\n",
      "          std_second                     better  \n",
      "Accuracy    0.053822  No significant difference  \n",
      "Precision    0.23017  No significant difference  \n",
      "Recall      0.191376                 KNNVariant  \n",
      "F1 Score    0.206701                 KNNVariant  \n",
      "Comparison results saved to Results/comparison_results_with_normality_2.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_rel, shapiro, wilcoxon\n",
    "\n",
    "# Load the summary data for both benchmarks\n",
    "results_folder = 'Results'  # Define the results folder\n",
    "first_summary_file = os.path.join(results_folder, 'summary_first_analysis.csv')\n",
    "second_summary_file = os.path.join(results_folder, 'summary_additional_analysis.csv')\n",
    "\n",
    "first_df = pd.read_csv(first_summary_file)\n",
    "second_df = pd.read_csv(second_summary_file)\n",
    "\n",
    "# Merge the summaries on the 'Dataset' column\n",
    "merged_df = pd.merge(first_df, second_df, on='Dataset', suffixes=('_first', '_additional'))\n",
    "\n",
    "# Function to perform normality test and statistical comparison\n",
    "def compare_metrics(metric):\n",
    "    print(f'\\nComparing {metric}:')\n",
    "    \n",
    "    first_values = merged_df[f'Mean {metric}_first']\n",
    "    second_values = merged_df[f'Mean {metric}_additional']\n",
    "    differences = first_values - second_values\n",
    "    \n",
    "    # Shapiro-Wilk test for normality\n",
    "    stat, p_value_shapiro = shapiro(differences)\n",
    "    print(f'Shapiro-Wilk test for normality of differences in {metric}: statistic = {stat:.3f}, p-value = {p_value_shapiro:.3f}')\n",
    "    \n",
    "    if p_value_shapiro > 0.05:\n",
    "        print(f'Differences in {metric} are normally distributed. Using paired t-test.')\n",
    "        # Paired t-test\n",
    "        t_stat, p_value_ttest = ttest_rel(first_values, second_values)\n",
    "        print(f'Paired t-test for {metric}: t-statistic = {t_stat:.3f}, p-value = {p_value_ttest:.3f}')\n",
    "        test_result = (t_stat, p_value_ttest, 't-test')\n",
    "    else:\n",
    "        print(f'Differences in {metric} are not normally distributed. Using Wilcoxon signed-rank test.')\n",
    "        # Wilcoxon signed-rank test\n",
    "        w_stat, p_value_wilcoxon = wilcoxon(first_values, second_values)\n",
    "        print(f'Wilcoxon signed-rank test for {metric}: w-statistic = {w_stat:.3f}, p-value = {p_value_wilcoxon:.3f}')\n",
    "        test_result = (w_stat, p_value_wilcoxon, 'Wilcoxon')\n",
    "    \n",
    "    # Calculate means and standard deviations\n",
    "    mean_first = first_values.mean()\n",
    "    std_first = first_values.std()\n",
    "    mean_second = second_values.mean()\n",
    "    std_second = second_values.std()\n",
    "    \n",
    "    # Determine which algorithm is better based on the means\n",
    "    if test_result[1] < 0.05:  # If the difference is statistically significant\n",
    "        if mean_second > mean_first:\n",
    "            better = 'KNNVariant'\n",
    "        else:\n",
    "            better = 'KNNClassifier'\n",
    "    else:\n",
    "        better = 'No significant difference'\n",
    "    \n",
    "    return test_result + (mean_first, std_first, mean_second, std_second, better)\n",
    "\n",
    "# Metrics to compare\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "\n",
    "# Compare metrics\n",
    "results = {}\n",
    "for metric in metrics:\n",
    "    stat, p_value, test_used, mean_first, std_first, mean_second, std_second, better = compare_metrics(metric)\n",
    "    results[metric] = {\n",
    "        'statistic': stat,\n",
    "        'p-value': p_value,\n",
    "        'test': test_used,\n",
    "        'mean_first': mean_first,\n",
    "        'std_first': std_first,\n",
    "        'mean_second': mean_second,\n",
    "        'std_second': std_second,\n",
    "        'better': better\n",
    "    }\n",
    "\n",
    "# Display the results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print('\\nComparison Results:')\n",
    "print(results_df)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "comparison_results_file = os.path.join(results_folder, 'comparison_results_with_normality_2.csv')\n",
    "results_df.to_csv(comparison_results_file)\n",
    "print(f'Comparison results saved to {comparison_results_file}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2263e7ad-7907-4c20-a084-3858c93a1ec3",
   "metadata": {},
   "source": [
    "**Accuracy**:\n",
    "- Shapiro-Wilk test: Differences are not normally distributed (statistic = 0.772, p-value = 0.007).\n",
    "- Wilcoxon signed-rank test: The difference in Accuracy is not statistically significant (w-statistic = 12.000, p-value = 0.131).\n",
    "- Mean Accuracy: KNNClassifier = 0.9156, KNNVariant without Weights = 0.9109\n",
    "- Conclusion: There is no significant difference in Accuracy between KNNClassifier and KNNVariant without Weights.\n",
    "\n",
    "**Precision**:\n",
    "- Shapiro-Wilk test: Differences are normally distributed (statistic = 0.912, p-value = 0.293).\n",
    "- Paired t-test: The difference in Precision is not statistically significant (t-statistic = 1.622, p-value = 0.139).\n",
    "- Mean Precision: KNNClassifier = 0.6289, KNNVariant without Weights = 0.5924\n",
    "- Conclusion: There is no significant difference in Precision between KNNClassifier and KNNVariant without Weights.\n",
    "\n",
    "**Recall**:\n",
    "- Shapiro-Wilk test: Differences are normally distributed (statistic = 0.912, p-value = 0.293).\n",
    "- Paired t-test: The difference in Recall is statistically significant (t-statistic = -4.641, p-value = 0.001).\n",
    "- Mean Recall: KNNClassifier = 0.3184, KNNVariant without Weights = 0.3685\n",
    "- Conclusion: KNNVariant without Weights significantly improves Recall compared to KNNClassifier.\n",
    "\n",
    "**F1 Score**:\n",
    "- Shapiro-Wilk test: Differences are normally distributed (statistic = 0.886, p-value = 0.155).\n",
    "- Paired t-test: The difference in F1 Score is statistically significant (t-statistic = -2.570, p-value = 0.030).\n",
    "- Mean F1 Score: KNNClassifier = 0.4076, KNNVariant without Weights = 0.4449\n",
    "- Conclusion: KNNVariant without Weights significantly improves F1 Score compared to KNNClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fe6c38-1528-4d14-b130-5936772702b4",
   "metadata": {},
   "source": [
    "In conclusion, the **KNNVariant**, both with and without distance weights, significantly enhances the performance in terms of recall and F1 score for imbalanced binary classification tasks. The distance weights **do not** appear to play a **crucial role** in improving these metrics. Therefore, KNNVariant with dynamic K and without distance weights might be recommended for use in imbalanced scenarios, as it simplifies the model while still achieving substantial improvements in critical performance metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda92c41-843c-4167-bd78-9e5047a08428",
   "metadata": {},
   "source": [
    "<a id=\"7-References\"></a>\n",
    "## 7. References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fd6efe-ab51-4a69-88c5-be9a462f1a27",
   "metadata": {},
   "source": [
    "[BOOKS]\n",
    "\n",
    "- A General Introduction to Data Analytics, 2018. J. Moreira, A. Carvalho, and T. Horvath - John Wiley & Sons, ISBN: 978-1-119-29626-3\n",
    "\n",
    "- ExtraÃ§Ã£o de Conhecimento de Dados: Data Mining, 2017. J. Gama, A. Carvalho, K. Faceli, A. Lorena, and M. Oliveira - SÃ­labo, ISBN: 978-972-618-914-5\n",
    "  \n",
    "- \"k-Nearest Neighbour Classifiers 2nd Edition (with Python examples)\". Cunningham, PÃ¡draig, and Sarah Jane Delany. \"k-Nearest Neighbour Classifiers 2nd Edition (with Python examples).\" arXiv preprint. arXiv:2004.04523 (2020). https://arxiv.org/abs/2004.04523\n",
    "\n",
    "[WEBSITES AND CODE]\n",
    "\n",
    "- https://github.com/rushter/MLAlgorithms\n",
    "\n",
    "- https://github.com/PadraigC/kNNTutorial\n",
    "\n",
    "- https://chatgpt.com\n",
    "\n",
    "- https://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7555df-c059-40e2-a0fd-1bedc13d346b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
